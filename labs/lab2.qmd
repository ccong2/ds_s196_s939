---
title: "Exploratory Data Analysis with ![](../img/Rlogo.png){width=60px}"
subtitle: <span style="color:#2C3E50">11.S939 Applied Data Science for Cities</span>
date: "Last Updated `r Sys.Date()`"
format: html
editor: visual
---

# Overview

This week's Lab Exercise focuses on the [dplyr](https://dplyr.tidyverse.org/index.html) package and the [ggplot2](https://ggplot2.tidyverse.org) package. It also begins to engage with data visualization best practices by demonstrating how to create and interpret a variety of graphics.

**Exploratory data analysis (EDA)** is a phase of a larger data science workflow that emphasizes getting to know the data before rushing to analyze it. EDA typically involves the creation and interpretation of **graphics** in order to build familiarity and gain fundamental insights that can inform more sophisticated analyses later on. There are several overarching goals of exploratory data analysis, including:

1.  To determine if there are any problems with your dataset.
2.  To determine whether the question you are asking can be answered by the data that you have.
3.  To begin formulating an answer to your question.

# Our study topic today

In the 2017 [Tax Cuts and Jobs Act](https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.pdf), a new federal incentive was introduced to encourage investment in low-income and undercapitalized communities. States were given the chance to select specific census tracts as Opportunity Zones, where investors could enjoy tax benefits for their eligible investments. Although, there's been [a lot of curiosity](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones) among practitioners and researchers regarding how effective the program is and whether the designations made by governors were successful.

If you are interested in the locations of these Opportunity Zones, you can check out [this map](https://www.arcgis.com/apps/View/index.html?appid=77f3cad12b6c4bffb816332544f04542). The brown geometries reflected on the map are [census tracts](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_13), which are statistical subdivisions of a county for collecting demographic and socioeconomic information about inhabitants. Find a familiar place for you, and see which areas have been designated as Opportunity Zones.

## Download data and load packages

Download the Lab 2 folder provided on Canvas. Initiate RStudio by double-clicking the .Rproj file.

Now please navigate to Urban Institute's website about [Opportunity Zones](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones), find the link **"Download tract-level data on all Opportunity Zones"**, and **download this dataset** to your "data" folder within your Lab 2 project folder.

Start a new .qmd file and remove the template texts.

To stay organized, we should load packages at the beginning of our markdown document. These are the three packages we are going to use today. *You may want to run `install.packages()` on `readxl` and `DataExplorer` if it's the first time you use them.*

```{r label="Load R Packages", message=FALSE, warning=FALSE}
library(readxl)
library(tidyverse)
library(DataExplorer)
```

# Read and examine our data

The file we've downloaded is in the Microsoft Excel ".xlsx" format. But it's not a problem at all. We can use `read_xlsx` from the `readxl` package to read these files.

`ozs <- read_xlsx("data/urbaninstitute_tractlevelozanalysis_update01142021.xlsx")`

```{r label="Read data", message=FALSE, warning=FALSE, include=FALSE}
ozs <- read_xlsx("../data/urbaninstitute_tractlevelozanalysis_update01142021.xlsx")
```

In the "Environment" panel on the top-right of your R interface, you should see the new object `ozs`. **Click it to preview its content**. (Alternatively, you can preview it by typing `View(ozs)` in your console).

This data lists tracts nationwide that are eligible to be designated as Opportunity Zones, whether they have been designated as Opportunity Zones or not, along with essential Census demographic data that describe these tracts. You can also see this dataset has 42,178 observations (rows) and 27 variables (columns).

Here are the column definitions:

-   **geoid**: combined state, county, tract FIPS (Federal Information Processing Standards) code this is a unique identification number for each census tract. If it is the first time you heard of tracts, they are sub-areas of a county defined for the purpose of taking a census.
-   **state**: the name of the state
-   **county**: the county name
-   **Designated**: 1 when an eligible tract was designated as an opportunity zone, and NA where the tract was not designated.
-   **Type**: category for OZ designation
-   **Population**: total population of the tract
-   **PovertyRate**: poverty rate
-   **medhhincome**: median household income
-   **medrent**: median gross rent (per month)
-   **medvalue:** median house value
-   **vacancyrate**: residential vacancy rate
-   **unemprate:** unemployment rate
-   **pctwhite**: White non-Hispanic population (%)
-   **pctblack**: Black non-Hispanic population (%)
-   **pctHispanic**: Hispanic and Latino population (%)
-   **Metro**: tract in a metropolitan area

------------------------------------------------------------------------

With all the data compiled, what this dataset might be able to tell us? For example, here are something I'm interested to know:

-   How many of these eligible census tracts are designated as Opportunity Zones, and how many are not designated? What is the situation at the federal, state, and county levels?
-   Are there any distinguishable differences in economic conditions between designated and not designated census tracts? Differences in terms of poverty rate, vacancy rate, median household income, demographics, etc.

## Initial data cleaning

The Urban Institute has coded the designated variable as either taking a value of 1 when designated, or *NA* when not. We can recode the *NA* values in `DesignatedOZ` for legibility. In the following code, we use the `dplyr` function: `mutate` to modify `DesignatedOZ` in place. We replaced the numbers with texts since the *NA* and 1 here have no mathematical meaning.

```{r label="recode", message=FALSE, warning=FALSE}
ozs <- ozs |>
  mutate(DesignatedOZ = case_when(
    DesignatedOZ == 1 ~ "Designated",
    is.na(DesignatedOZ) ~ "Not Designated"
  ))
```

This modification will make it much easier for us to make a quick count of both types of areas.

```{r label="count", message=FALSE, warning=FALSE}
ozs |> 
  count(DesignatedOZ) 
```

There are a few columns (such as `SE_Flag`) that wont' be very helpful for this analysis. We can `select` a subset of columns to work on. If there is a minus sign in front of the column names, that means to drop these specified columns.

```{r label="select", message=FALSE, warning=FALSE}
ozs <- ozs |> 
  select(-c(dec_score, SE_Flag, pctown, Metro, Micro, NoCBSAType))
```

One of the characteristics tracked in the Urban Institute data is the median household income for each tract. We might question whether there's a difference in the median household income for designated and not-designated census tracts. Let's see if we can calculate the mean of the median household income values:

```{r label="mean-1", message=FALSE, warning=FALSE}
mean(ozs$medhhincome)
```

It returns *NA*. But it doesn't indicate an issue with our code. The reason for this is the presence of missing values in this column. When dealing with numerical variables, *NA* values affect calculation results because we can't decide if the missing values are larger or smaller than the others and we don't know how to calculate them.

Sort the `medhhincome` column by clicking the little triangles appearing on the column name. Drag down to the bottom of the dataset, then you will see quite a few of *NA*s in the Census demographic columns.

How many missing values are there, and how many would be a hurdle for my analysis? It will be great to have a sense of completeness in terms of what proportion of a field actually holds data. `DataExplorer` is a handy tool that offers functions to quickly understand the completeness of datasets.

```{r label="missingvalues", message=FALSE, warning=FALSE}
DataExplorer::plot_missing(ozs)
```

`plot_missing` calculates the proportion of missing values in a given variable, and makes some judgemental calls of whether the missing is significant, indicated by "Good", "OK", and "Bad". (Check out the documentation by typing `?plot_missing` in your console. What are the default ranges for these three categories?) Overall, most of our columns have a very small percentage of missing values (less than 1%) and would not create significant representative issues. However, when performing calculations, we need to include the `na.rm = TRUE` argument, indicating that we are calculating based on the available 99%.

```{r label="mean-2", message=FALSE, warning=FALSE}
mean(ozs$medhhincome, na.rm = TRUE)
```

With that, we can calculate the average median household income for designated and not-designated census tracts using `group_by` + `summarise`.

```{r message=FALSE, warning=FALSE}
ozs |> 
  group_by(DesignatedOZ) |> 
  summarise(
    Tracts = n(),
    Income = mean(medhhincome, na.rm=TRUE))
```

We could summarize based on two groups - summarize first by state than by legibility - so that we have such comparisons for each state.

```{r message=FALSE, warning=FALSE}
ozs |> 
  group_by(state, DesignatedOZ) |> 
  summarise(
    Income = mean(medhhincome, na.rm=TRUE))
```

It might be useful for us to reshape our summary table so that there is one row for each county, with each row containing the summary value for both designated and not designated tracts.

The two commands `pivot_wider()` and `pivot_longer()` are useful for reshaping our data. `pivot_wider()` essentially adds columns to a dataset by transitioning content from rows to columns. `pivot_longer()` does the opposite - it makes a dataset longer by transitioning columns to rows.

In our case, let's use `pivot_wider()` to transition our Designated and Not Designated rows into columns.

```{r message=FALSE, warning=FALSE}
ozs |> 
  group_by(state, DesignatedOZ) |> 
  summarise(
    Income = mean(medhhincome, na.rm=TRUE)) |> 
  pivot_wider(names_from = DesignatedOZ, values_from = Income)
```

That makes it easier to calculate and show the difference in income between designated and not designated tracts:

```{r message=FALSE, warning=FALSE}
ozs |> 
  group_by(state, DesignatedOZ) |> 
  summarise(
    Income = mean(medhhincome, na.rm=TRUE)) |> 
  pivot_wider(names_from = DesignatedOZ, values_from = Income) |> 
  mutate(Difference = Designated - `Not Designated`)
```

## Exercise 1

While we are now examining the nationwide dataset, you are going to conduct some focused analysis for Massachusetts. Please **insert a new code chunk below to create a new object `ozs_ma` that extracts all tracts in Massachusetts**. Then add some more code chunks and texts to document your responses to the following questions.

1.  In Massachusetts, how many eligible census tracts are designated as Opportunity Zones, and how many are not designated?

    -   Which function or approach did you use to answer this question?

2.  Choose **one of** the following variables: `medhhincome`, `vacancyrate`, `unemprate`, `pctwhite`, `pctblack`, `pctHispanic`, `pctover64`, `HSorlower`.

    Say that you have chosen `unemprate`:

    -   What are the 'average unemployment rate' for both designated and not designated tracts in **Massachusetts**?
    -   What is the **difference** in the 'average unemployment rate' between designated and non-designated tracts within **Middlesex County**?
    -   **Which county** has the greatest disparity in 'average unemployment rates' between designated and non-designated tracts?

# Generate Diagnostic Graphs

## Distribution of one variable

### Box Plot

Now we are ready to create some visual representations of our data. The code below creates a **boxplot** to contrast the distribution of poverty rates between designated opportunity zones and undesignated zones. We are using what should now be familiar conventions to construct the graphic beginning with the `ggplot` function, then adding more features with the `+` operator and other functions [listed in the package reference](https://ggplot2.tidyverse.org/reference/index.html).

-   `ggplot(data = ozs)`: This is the main plotting function. `ozs` is your dataset we use.
-   `geom_boxplot()`: Recall that geometric layers are called **geoms**. It tells R what kind of geometry you want to use visualize the data.
-   `aes(x = DesignatedOZ, y = PovertyRate)`: The `aes()` function is where you tell `ggplot` which variable goes on the x axis followed by which variable goes on the y axis.
-   The third aesthetic element is `fill`, which indicates the filled color of the boxplot. Accordingly, we use the `fill` argument in the `labs` function to set the name of the legend.
-   We used a new function `scale_y_continuous` to specify y axis properties. Here we are making sure the poverty rate are labeled as **percentages**. If you remove this line, they will by default show as decimal numbers.

```{r label="boxplot", message=FALSE, warning=FALSE}
ggplot(data = ozs) +
  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), na.rm = TRUE) + 
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Opportunity Zone Eligible Tracts", y = "Poverty Rate", fill = "Tracts")
```

By comparing *the 50th percentile* (the horizontal line inside each box) we can see that tracts designated as Opportunity Zones have a higher poverty rate compared with those not designated. The *heights* of the boxes themselves give us an indication of how closely around the median all values in the dataset are concentrated---the degree of dispersion or spread. The *vertical lines* are called whiskers and extend upward and downward to the lowest values that are not candidates for outlier status. An *outlier* is an unusual value that could potentially influence the results of an analysis. These are indicated with dots in the boxplot.

Outliers can be legitimate values, and require the exercise of judgment on the part of the analyst and may be removed or excluded from the analysis or imputed. There are a variety of criteria that have been offered, but you will address this question from a more statistical perspective in your other courses that introduce linear methods.

### Density plot

By modifying the last code chunk, we can make a **density plot** to describe the distribution of poverty rate. A density plot can be understood as a smoothed version of the histogram, and provides a more direct view of of the shape and peaks in the data. The x-axis typically represents the range of values for the variable of interest, while the y-axis represents the probability density (how likely it is for the variable to take on a particular value within that range).

```{r label="densityplot", message=FALSE, warning=FALSE}
ggplot(data = ozs) +
  geom_density(aes(x = PovertyRate, fill = DesignatedOZ), na.rm = TRUE) + 
  scale_x_continuous(labels = scales::percent) +
  labs(x = "Poverty Rate", fill = "Tracts")
```

If you have noticed - in the code above, we didn't provide a variable that what goes to the y-axis. Where does the value "density" come from?

Many graphs, like boxplot, plot the raw values of your dataset. But other graphs, like histograms and density plots, calculate new values to plot. Here a density takes the count of data points at discrete poverty rate levels and smooths it out into a continuous curve. Then calculated values (probability density) go to the y-axis.

### Combinations of basic graphs to create composite views

One of the coolest thing about `ggplot` is that we can plot multiple `geom_` on top of each other. For instance, we can combine the two plots above, to show both visually appealing curves and essential statistics (medians, quartiles, outliers, etc.) The following code uses two `geom_`([Check out `geom_violin` for more](https://ggplot2.tidyverse.org/reference/geom_violin.html#:~:text=A%20violin%20plot%20is%20a,same%20way%20as%20a%20boxplot.)!), and introduces several new and helpful arguments for fine-tuning the cosmetics.

-   `trim = FALSE`: If TRUE (default), trim the tails of the violins to the range of the data. If FALSE, don't trim the tails and show the complete distribution.
-   `alpha = 0.5`: the transparency of the plotting area.
-   `coord_flip()`: whether the y axis is displayed horizonally or vertically.
-   `legend.position = "none"`: the position of legend ("left", "right", "bottom", "top", or two-element numeric vector), or not showing the legend ("none").

```{r label="extra-1", message=FALSE, warning=FALSE}
ggplot(ozs) +
  geom_violin(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), trim = FALSE, alpha = 0.5) +
  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate), colour = "black", width = .15, alpha = 0.8) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    x = "Opportunity Zone Eligible Tracts",
    y = "Poverty Rate",
    title = "Distribution of Poverty Rate"
  ) +
  coord_flip() +
  theme(legend.position = "none")
```

## Exercise 2

Focus on your selected variable in Exercise 1 and your data specific to Massachusetts. Explore the distribution of your variable of interest.

1.  Create one graphical representation that contrasts the results in designated tracts and in undesignated tracts in Massachusetts.
2.  Interpret the graphic you have created and include 2-3 sentences of text explanation, for example:
    -   Is it a more flat/homogeneous distribution, or a more skewed distribution in terms of fewer observations belonging to the higher-value groups? Does that align with your expectation for this variable?

    -   What can we say about the difference in demographic/economic conditions between designated and not designated census tracts in Massachusetts?

    -   Feel free to consult the [R Graph Gallery](#0) and [Aesthetic specifications](https://ggplot2.tidyverse.org/articles/ggplot2-specs.html) for additional resources.

## Relationship between two variables

### Scatter Plot

We are often interested in bivariate relationships or how two variables relate to one another. **Scatterplots** are often used to visualize the association between **two** **continuous variables**. They can reveal much about the [nature of the relationship](https://www.jmp.com/en_hk/statistics-knowledge-portal/exploratory-data-analysis/scatter-plot.html) between two variables.

Let's use your subset of **Massachusetts data** to perform this part of analysis. (We could use the nationwide dataset, but there will be over 40,000 points showing on the graph, which will not be pleasing to the eye).

```{r label="massachusetts", echo=FALSE}
ozs_ma <- ozs |> filter(state == "Massachusetts") 
```

We begin by creating a scatterplot of poverty rate and unemployment rate. Note that we used `theme_bw`, which is a [`theme` template](https://ggplot2.tidyverse.org/reference/ggtheme.html) for a cleaner look.

```{r label="Scatterplot", message=FALSE, warning=FALSE}
ggplot(ozs_ma) +
  geom_point(aes(x = unemprate, y = PovertyRate)) +
  labs(x = "Unemployment rate",
       y = "Poverty rate",
       title = "Poverty rate vs. unemployment rate in Opportunity Zone eligible tracts", 
       subtitle = "State of Massachusetts",
       caption = "Source: Urban Institute (2018)") + 
  theme_bw()
```

It is generally easy to recognize patterns in a graphical display. As we move from left to right along the x-axis (i.e., as the unemployment rate creases), the amount of poverty rate reported also increases.

As a complement to a scatterplot, we can use the `stats::cor` function to calculate the (Pearson by default, see `?cor` for other options) **correlation** between any continuous variables in the dataset. The `DataExplorer` package is also designed to help us quickly understand patterns in our data. We demonstrate both in the following code.

If you are unfamiliar with reading a correlation matrix, the values range between -1 and 1 where:

-   -1 indicates a perfectly negative linear correlation between two variables
-   0 indicates no linear correlation between two variables
-   1 indicates a perfectly positive linear correlation between two variables

```{r label="correlation-1", message=FALSE, warning=FALSE}
ozs_ma |> select(Population:medrent, pctwhite:BAorhigher) |> 
  stats::cor(use = "complete.obs")
```

```{r label="correlation-2", message=FALSE, warning=FALSE}
ozs_ma |> select(Population:medrent, pctwhite:BAorhigher) |> 
  na.omit() |> 
  DataExplorer::plot_correlation()
```

An additional note to the code above is that we selected several continuous variables that we want to inspect, and removed NA values (`use = "complete.obs"`) so that the correlation values can be correctly calculated.

What can we do if we are interested in statistical associations between **categorical variables**? The typical approach is to use a chi-squared test (see the `chisq.test` function in the `stats` package) in conjunction with visual tools like **barcharts**. We won't delve deeply into the statistical aspect, but we will learn the useful bar plots for displaying summary statistics of categorical data.

### Bar plot

In the following code, you can see our familiar `group_by` + `summarise` process used to calculate the average median house income by county in Massachusetts. This summarized table is then piped to `ggplot()` for visualization.

```{r label="barchart", message=FALSE, warning=FALSE}
ozs_ma |> 
  group_by(county, DesignatedOZ) |>  
  summarise(
    Tracts = n(),
    Income = mean(medhhincome, na.rm=TRUE)) 
```

## Exercise 3

1.  Building on the last code block, add `ggplot()` to produce a barchart that shows the summarised income of both designated tracts and undesignated tracts in each county.

    You are going to decide what `geom_` to use and what to put into the `aes()` .

------------------------------------------------------------------------

2.  After you have produced your graph, take a few minutes to read this bar chart below:

![](../img/lab2-emp.png)

There should be a few differences in this graph compared with what a default function would give us. How can you modify your code above to replicate the bar chart in this image? **In a new code chunk,** please copy and paste your last bar chart code, and try your best to address the following questions.

1.  The bars are put side-by-side instead of stacking on top of one another. [More explainations here](https://r4ds.had.co.nz/data-visualisation.html#position-adjustments). If you don't want a stacked bar chart, you can use one of the three other options: "identity", "dodge", or "fill".
2.  The x-axis labels are titled to 45 degrees. How can I achieve this? [Hint](https://ggplot2.tidyverse.org/reference/theme.html).
3.  The labels on the y-axis are formatted in thousands with commas. This can be achieved by modifying the function `scale_y_continuous(labels = scales::percent)` we have seen before. [Hint](https://ggplot2.tidyverse.org/reference/scale_continuous.html).
4.  Lastly, the counties are not arranged alphabetically, but rather by the income values mapped to the y-axis, starting from large to small. How can I achieve this? [Hint](https://blog.albertkuo.me/post/2022-01-04-reordering-geom-col-and-geom-bar-by-count-or-value/).
5.  Please add the title, subtitle, x- and y-axis labels, and the data source annotation to your bar chart.
6.  Please choose a [theme template](https://ggplot2.tidyverse.org/reference/ggtheme.html) for your bar chart.

## Bonus: Scatterplot with marginal histograms

This is just for fun - If you want to create more advanced statistical plots, there are ways to do that too. The following graph requires an additional package `ggExtra`. But the other syntax should be familiar now.

```{r label="extra-2", message=FALSE, warning=FALSE}
#install.packages("ggExtra")
p <- ggplot(ozs_ma) + 
  geom_point(aes(x = pctBlack, y = PovertyRate, color = DesignatedOZ)) + 
  theme_bw()
ggExtra::ggMarginal(p, type = "histogram", groupFill = TRUE)
```

# Work Products

Please submit **a .qmd file** and **a** **knitted HTML file** that shows your work and responses for each of the **three** **Exercises** included in this lab.

Include in your document a short write-up of approximately 200 words, that looks back on our questions when we started and discusses what you have found from our analysis so far, with a focus on the State of Massachusetts. You can connect your findings with some broader discussions about Opportunities Zones found [here](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones).

A quick tip: if you include `self_contained = TRUE` in your YAML header, you can create a standalone HTML document without losing the pictures.

![](/img/lab3-html.PNG)

Please **upload your report to Canvas** **by the end of day, Tuesday, Nov 7.**

### 
