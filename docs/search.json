[
  {
    "objectID": "syllabus/index.html",
    "href": "syllabus/index.html",
    "title": "Applied Data Science for Cities",
    "section": "",
    "text": "Description\nUrban data science draws upon statistics, visualization, and computation to better understand and ultimately shape cities. This course emphasizes telling stories about cities using a set of descriptive approaches, quantitative and spatial analysis in R. We will learn how to describe community characteristics with small area census data, work with local administrative data, and think about how our analysis of quantitative data fit with other forms of data and engagement to fill in gaps in knowledge.\nLearning objectives:\n\nLearn - begin developing core data science competencies such as data wrangling, visualization, analysis, and communication;\nApply - apply concepts introduced in the readings and lectures to analyze datasets drawn from cities around the world;\nVisualize - manipulate tabular and geospatial data to produce intelligible and useful graphics for inclusion in documents and dissemination on the web;\nSynthesize - translate the results of visualization and analysis for use in decision-making and policy development.\n\n\nHow Will We Be Learning\nLecture: Class meetings are generally divided into lecture (Mondays) and laboratory sessions (Wednesdays) that focus on concepts and hand-on applications, respectively.\nLab: We will provide data science tutorials using R. Each lab tutorial aims to solve a specific urban data science problem in addition to building coding skills. Lab reports are due before the subsequent lab session and should be written independently.\nExtension readings: We provide a light material list that focuses on specific topics each week. These resources are meant to expand your knowledge and enhance your project completion capabilities.\nUrban data science project: The term project for the course will focus on integrating the tools of data science to explore a specific real-world planning issue or research question. This is a group project and students will define the scope of the project and identify specific deliverable(s) early in the semester. Reproducing an existing analysis or study using different datasets or an alternate study area is also acceptable for the term project.\n\n\nPrerequisites\nThis is a relatively fast-paced course so students can benefit from some prior knowledge working in R and RStudio. However, this is not a course prerequisite. Our first course sessions will focus on ensuring that we are all familiar with some of the basic work environment and methods which we'll make use of over the semester.\n\n\nAssessment\n\n\n\nAssignment\nWeight\n\n\nLab Reports\n50%\n\n\nProject Proposal\n10%\n\n\nProject Presentation\n30%\n\n\nAttendance\n10%\n\n\n\n\n\nKey Logistics\nLab Reports: You will be working on lab on most Wednesday classes and submit a short report before the next lab session. Details will be specified in each assignment submission page on Canvas.\nProject Proposal: Due Monday, Nov 18.\nThe purpose of this memo is to communicate the scope of your project (what you will do) and your strategies for collecting, visualizing, and analyzing data (how you will do it). A separate guideline will be distributed at the beginning of the course.\nProject Presentation: Week 8 (Dec 9 – Dec 11), class time. Presentations slides will due Dec 9.\n\n\nLate policy\nTo keep all students on a relatively level playing field, 5% will be deducted for late assignments, with an additional 5% deducted for each subsequent day. Late assignments two weeks after the due date will receive no credit and will not be accepted.\n\n\nSoftware\nWe use R and R Studio as the coding environment to develop analysis and applications. You will need to install both software on your personal computers from hereLinks to an external site. and hereLinks to an external site..\n\n\nCommunication\nPlan on using our class Slack channel, email, and office hours to get help with troubleshooting problems as they arise in your work. I also encourage you to work with others in the class to troubleshoot problems - it is highly likely that others in the class have encountered similar problems, and this also allows us to create a repository of our problems and responses.\nEmail: I check emails quite frequently, but I will not always be able to respond to emails right away. Please plan accordingly so that you don't miss deadlines.\nSlack: We have a Slack workspace that is accessible through Canvas for general communication, including homework Q&A, resource exchange, project collaboration, etc.\nOffice hours: Please consult the top of the syllabus for specific times. I will announce if there are any changes or exceptions. I'm happy to answer any specific coding questions, or chat and help shape the objective and scope of your projects.\n\n\nEthics\nAcademic Integrity: Violations to academic integrity are unacceptable at MIT and DUSP. Instances of misconduct include but are not limited to plagiarism, cheating, and deliberately unauthorized use of course data and material.\nCollaboration Policy: While team collaboration is encouraged, students should specify their roles and tasks in a project. A positive and constructive attitude toward teamwork is essential for the successful completion of the course.\nDiversity and Inclusion: MIT highly values a diverse, friendly, respectful, and inclusive learning environment among students, faculty, and staff. We welcome all individuals regardless of their origin, citizenship, gender identity, sexual orientation, or religious and political beliefs. Please contact me or departmental staff if you have any questions / considerations regarding this."
  },
  {
    "objectID": "labs/lab5.html",
    "href": "labs/lab5.html",
    "title": "Download and analyze Census data with ",
    "section": "",
    "text": "In this lab, we will use decennial census data and American Community Survey (ACS) data to examine long-term population trends in neighborhoods. These are common sources of historic sociodemographic information, including those that have been pre-processed by sources other than the Census Bureau.\nThe Nathalie P. Voorhees Center has conducted research on neighborhood and community improvement in the City of Chicago. In this example below, they calculate the average per capita income for each census tract in Chicago for the years 1970, 1980, 1990, 2000, 2010, and 2017, and then compare it to the regional weighted average income. They have found Chicago has become more segregated by income over time and is losing its middle class.\nThe study also overlays recent demographic characteristics based on these changes. In the following image, the census tracts are classified into “three cities”: those that have increased their share of regional income by 20% or more, those that have changed by less than 20%, and those that have decreased by 20% or more.\n\nWe will take the idea of the Voorhees Center’s study to examine population change patterns in Chicago. Chicago has experienced population decline since its peak in the mid-20th century, attributed to factors including the decline of manufacturing, suburban expansion, and demographic shifts - a phenomenon identified by urban scholars as “Shrinking Cities”. We will use historic population census data to show how the trend manifests in Chicago and how it affects across different areas of the city.\nGo ahead and start a new .qmd file and remove the template texts, as we always do. These are the packages we are going to use today.\n# You may need to install the packages: tigris, sf and gt\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(sf)\nlibrary(gt)\n\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(sf)\nlibrary(gt)"
  },
  {
    "objectID": "labs/lab5.html#acs-data-in-2022",
    "href": "labs/lab5.html#acs-data-in-2022",
    "title": "Download and analyze Census data with ",
    "section": "ACS data in 2022",
    "text": "ACS data in 2022\nWe will first use tidycensus to download data for 2022, you’ll need a Census API key (Here is where you can request one from the census bureau). After you’ve signed up for an API key, be sure to activate the key from the email you receive from the Census Bureau so it works correctly.\nDeclaring install = TRUE when calling census_api_key() will install the key for use in future R sessions, which may be convenient for many users.\ncensus_api_key(\"yourkeyinquotationmarks\", install = TRUE)\nTo complete the API call for ACS data, you will typically need to specify:\n\nA desired geography to look up (for example, tract- or block group-level data)\nThe variables we want to look up (we have the complete variable list for 2022 5-year ACS, you can also retrieve this list by calling load_variables())\nThe state and county names to define your study region.\nThe census year you want data for.\nThe survey you’d like to use (such as ACS 1-, or 5-year data)\n\nThe following code returns the number of total population by tract in Cook County, Illinois in 2022. The table we consult is B01001: Sex by Age.\n\nF_2022 &lt;- get_acs(\n  geography = \"tract\",\n  state = \"IL\",\n  county = \"Cook\",\n  variables = \"B01001_001\",\n  geometry = TRUE,\n  year = 2022)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |==============================                                        |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=====================================                                 |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\nNow you might have seen our first problem: we don’t have the option for getting tract-level data for cities. We can only obtained data for Cook County, where Chicago is located, but not for the City of Chicago directly. We will come back to it later in our exercise to cut out tracts within Chicago’s spatial boundary. That’s why we’ve included the argument geometry = TRUE, which will be needed for our spatial processing.\n\ngeometry = TRUE returns a simple features (sf) object with spatial information saved for each tract. The returned table will include a geometry variable that enables spatial analysis."
  },
  {
    "objectID": "labs/lab5.html#decennial-data-in-2010",
    "href": "labs/lab5.html#decennial-data-in-2010",
    "title": "Download and analyze Census data with ",
    "section": "Decennial data in 2010",
    "text": "Decennial data in 2010\nIn addition to get_acs(), tidycensus also provides get_decennial() for retrieving data from the US Decennial Census for the years 2000, 2010, and 2020. The function uses similar arguments, as shown below:\n\nF_2010 &lt;- get_decennial(\n  geography = \"tract\", \n  state = \"IL\",\n  county = \"Cook\",\n  variables = \"P001001\",\n  geometry = TRUE,\n  year = 2010)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=====================================                                 |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  76%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "labs/lab5.html#historic-data-in-1990-and-1970",
    "href": "labs/lab5.html#historic-data-in-1990-and-1970",
    "title": "Download and analyze Census data with ",
    "section": "Historic Data in 1990 and 1970",
    "text": "Historic Data in 1990 and 1970\nUnfortunately we cannot continue to use get_decennial() for the 1990 and 1970 data. The primary reason is the removal of these API endpoints by the Census Bureau. However, there are other factors at play.\n\nSurvey Changes: After the 2000 Census, the long form decennial survey transitioned into the American Community Survey (ACS).\nChanging Geographies: Census geographies, which approximate neighborhoods based on population, can change over time. While some tracts remain the same, others may be split if the population increases, or merged if the population decreases.\n\nAnalysts often face the challenge of geographic inconsistencies when working with longitudinal data. The Census Bureau’s geographic relationship files can help show the relationships between geographies over time. To make it easier for researchers, Brown University’s Longitudinal Tract Database offers demographic estimates for previous decennial census years—1970, 1980, 1990, and 2000—adjusted to match the 2010 boundaries. This means the tract areas and IDs match the 2010 data, with attribute values adjusted based on area or population share to reflect boundary changes over the years.\nLet’s get familiar with LTDB data and how to use them. Go to the data download page. You will need to enter your email address and certify that you will follow terms of use for the data.\nReview the data standard descriptions a bit to see what datasets are available. In our analysis, we will only use the full standard data files for population counts.\n\nIn “Download Standard Full Data Files”, select the year 1990, click the download button. Then do the same for 1970. It’s recommended to download them into a “data” folder in your project directory.\nNow we can import these two datasets using read_csv. Simultaneously, we’ll use filter() to extract only the portion for Cook County.\n\nF_1990 &lt;- \n  read_csv(\"../data/LTDB_Std_1990_fullcount.csv\") |&gt;\n  filter(county == \"Cook County\" & state == \"IL\")\n\nF_1970 &lt;- read_csv(\"../data/LTDB_Std_1970_fullcount.csv\")|&gt;\n  filter(county == \"Cook County\" & state == \"IL\")"
  },
  {
    "objectID": "labs/lab5.html#compare-population-changes",
    "href": "labs/lab5.html#compare-population-changes",
    "title": "Download and analyze Census data with ",
    "section": "Compare population changes",
    "text": "Compare population changes\n\nExercise 1\nWe have compiled population data in one table. To make this table more informative, let’s calculate the percentage change in population for each tract, and classify tracts based on whether their population has significantly decreased, increased, or remained largely unchanged, following the Voohver Center’s approach.\n\nPlease insert your own code into the document to achieve the following:\n\nCalculate the population change from 1970 to 2022 by computing the percentage increase (POP22 - POP70) / POP70. Use mutate() for this and create a new column called “change”.\nCreate another column called “status” to classify the changes. Label changes less than 10% as “Low Change”. Label changes greater than 10% as “Growing”, and less than -10% as “Declining”.\nNote that we also have missing values (NAs) in change due to differences in census tracts, where some tracts in 2020 did not exist in earlier years. To account for that I included a fourth category in status named “Uncategorized”.\n\nHint: How to populate values based on multiple conditions? The traditional and more straightforward approach is using the if_else() statement. Combining it with mutate, it looks something like this:\npop_data |&gt; \n  mutate(status = ifelse(change &lt; -0.1, \"declining\",\n                ifelse(change &gt; 0.1, \"growing\",\n                ifelse(is.na(change), \"uncategorized\", \"low change\"))))\nHowever, dplyr offers a more concise solution. Check out case_when, which simplifies handling multiple conditions by eliminating the need for nested if else statements within multiple parentheses."
  },
  {
    "objectID": "labs/lab5.html#create-summary-tables",
    "href": "labs/lab5.html#create-summary-tables",
    "title": "Download and analyze Census data with ",
    "section": "Create summary tables",
    "text": "Create summary tables\nWhen you are ready preparing the dataset in the last step. we can use group_by() and summarise() to find out how many tracts are in each category.\n{rlabel=\"sumtable1\", message = FALSE, warning=FALSE} pop_data |&gt; group_by(Status) |&gt;    summarise(`Number of Tracts` = n())\nSpeaking of summary tables, gt() is powerful tool for creating presentable and customizable tables with ease. For instance, we can add a few more lines in the previous code to enhance this table by adding titles and colorization. There are also many other styling options available.\n\npop_data |&gt; group_by(Status) |&gt; \n  summarise(`Number of Tracts` = n()) |&gt; \n  gt() |&gt; \n  tab_header(title = \"Change in Population, 1970-2022\",\n             subtitle = \"Cook County, IL\") |&gt; \n  tab_options(column_labels.background.color = 'dodgerblue4')\n\n\n\n\n\n  \n    \n      Change in Population, 1970-2022\n    \n    \n      Cook County, IL\n    \n    \n      Status\n      Number of Tracts\n    \n  \n  \n    Group 1 - Growing\n392\n    Group 2 - Declining\n621\n    Group 3 - Low Change\n273\n    Uncategorized\n46"
  },
  {
    "objectID": "labs/lab3.html",
    "href": "labs/lab3.html",
    "title": "Describe neighborhood dynamics with ",
    "section": "",
    "text": "In this lab, we will develop a place profile to quantify the physical and environmental characteristics of a given area. Planners are usually interested in understanding and enhance improving urban environments. Our approach will involve utilizing spatial data and conducting spatial analysis.\n\nTo put things into context, we will describe the built environment conducive to pedestrians in Boston neighborhoods. Much work in this field focuses on design guidelines that promote pedestrian friendliness. Urban factors such as the presence of walking facilities, the density and variety of businesses, the number of residents and jobs, and streetscape elements like benches, storefronts, and shade all influence the extent and nature of walkable areas (Frank et al., 2006; Owen et al., 2007; Jacobs, 1961; Lynch, 1960).\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(mapview)\nlibrary(osmdata)\nlibrary(scales)\n\nFor the purpose of demonstrating how to gather, combine and analyze spatial data from different sources, we are going to develop three relatively simple indicators to measure the pedestrian environment in a Boston neighborhoods: sidewalk density, restaurants measured by points of interest (POI), and street trees."
  },
  {
    "objectID": "labs/lab3.html#calculate-the-number-of-pois-by-neighborhood",
    "href": "labs/lab3.html#calculate-the-number-of-pois-by-neighborhood",
    "title": "Describe neighborhood dynamics with ",
    "section": "Calculate the number of POIs by neighborhood",
    "text": "Calculate the number of POIs by neighborhood\nWe have a point shapefile and a polygon shapefile, and now we want to count the number of points in each neighborhood. As you might have guessed, we’ll use st_intersection again.\n\ncount_restaurants &lt;- \n  st_intersection(restaurant, neighborhood) |&gt; \n  group_by(nbh_name) |&gt; \n  summarise(restaurant = n())\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries"
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Get started with ",
    "section": "",
    "text": "This practice exercise provides some more structured exploration and practice with Quarto Document (in R Markdown format). We will mix Markdown sections with code chunks, build familiarity with basic data types, and experiment with importing a tabular dataset. Because this is an in-class exercise, there is nothing you need to submit—the goal is to apply what we have read and seen in the lectures."
  },
  {
    "objectID": "labs/lab1.html#set-up-a-new-project",
    "href": "labs/lab1.html#set-up-a-new-project",
    "title": "Get started with ",
    "section": "Set up a New Project",
    "text": "Set up a New Project\nWe have talked about files paths in class, and the importance of explicitly setting a directory to work out of. Most of the time we can use setwd(), this works fine until when you want to move your working folder to another computer or share your work. If you explicitly set your working directory in the code, it won’t be able to access the directory that doesn’t exist on another computer.\nIn our labs, we are going to use R Projects to organize our works and make sure we don’t lose files during transfers. R projects organize all files related to a project in one place and setting up relative file paths. Let’s start by setting up a project for our exercise.\nLaunch RStudio, then click File - New Project... A dialog box will open up. Select New Directory, then New Project. Here, you can create a new folder to save everything related to this project. For example, I navigated to my D:/Fall24 folder and created a new folder there called Lab 1:\n\nClick the button “Create Project”. R will take a second to refresh. Then you will see in your Files tab that you have been directed to your current working directory: D:/Fall24/Lab 1. You will also see a .Rproj file in that folder.\n\nThe .Rproj file is the “key” that R references all project-related files. If you save all files related to Lab 1 in this folder, all relative paths remain intact and consistently applied.\nNote: In future labs, I may provide you with a project folder containing data. As long as you launch RStudio by double-clicking the .Rproj file, you will be taken directly to the project’s home directory."
  },
  {
    "objectID": "labs/lab1.html#practice-formatting-text-with-quarto",
    "href": "labs/lab1.html#practice-formatting-text-with-quarto",
    "title": "Get started with ",
    "section": "Practice formatting text with Quarto",
    "text": "Practice formatting text with Quarto\nNow go to File - New File - Quarto Document to create a new Quarto document. The prompt shown below will appear. Type in a document title (e.g. Lab 1) and your name. Keep the radio button for HTML selected.\n\nYou will then see a template file. At the very top you will see the YAML (or “Yet Another Markdown Language”) header which begins and ends with three dashes ---. The YAML header determines how your document will be rendered to your desired output format. Now it specifies the title, author, output format and text editor.\nTo get an idea of how everything works, let’s click the “Render” button on top of your toolbar.\nWhen prompted, give this file a name, it will be saved in the folder where your “.Rproj” file is.\nYou will see a formatted document in a web browser. Switch between them back and forth to see where each part of the code is placed in the rendered HTML file.\nNow we can add a new line to the YAML header:\n\ndate: &lt;insert the date that the file is created&gt;.\n\nRender it again and see where the difference is.\nThere can be other options specified in the YAML, particularly if you are rendering to a format other than HTML (see the reading from this week).\nOn the very left of this toolbar, click the “Source” button to switch Markdown editing mode. These sections of text typically explain or provide context for the code and graphics, and they are formatted using Markdown syntax. For example:\n\n#: a header element.\n**: bold text.\n*: italic text.\n` : code blocks.\n\nOverall, the Visual interface looks pretty much like a Word document. There is a toolbar that allows you to make bold or italic text, create a bullet list, insert a link or an image, insert a code block, etc.\nNow let’s delete everything below the YAML header in the template file, so that we will start creating our own formatted report.\n\nYour practice\nIn 2014, the City of Cambridge passed a local ordinance on building energy use disclosure. Spend a few moments reviewing this website to become familiar with the ordinance (in general). Then, add 2-3 sentences below your YAML section that explain the following:\n\nWhat does the Building Energy Use Disclosure Ordinance require?\nWhat kind of data have been compiled and where to find them?\n\nYou may edit your text either in the “Source” or “Visual” panel, or toggle between them to get familiar with both. Make sure to make gratuitous use of bold, italics, bullet points, etc. in your text. You have access to the “Markdown Quick Reference” directly from RStudio (Help - Markdown Quick Reference).\nWhen you finished, save your file and click Render again. You can immediately see your nicely formatted document in a web browser."
  },
  {
    "objectID": "labs/lab1.html#select-selects-a-subset-of-columns.",
    "href": "labs/lab1.html#select-selects-a-subset-of-columns.",
    "title": "Get started with ",
    "section": "Select: selects a subset of columns.",
    "text": "Select: selects a subset of columns.\nWhile in base R, we do:\ndataset[, c(\"Column1\", \"Column2\")]\nIn dplyr, we do:\ndataset |&gt; select(Column1, Column2)\nIn other words, we can simply insert the column names into the select function, without worrying about syntax like indexing, concatenation (c()), and the quotation marks.\nIn the energy dataset, we probably don’t need all of the 46 columns. So we can make it a smaller dataset by specifying a few columns to keep. Insert a new code chunk in your document like this one below. We will only keep 9 columns in the new dataset.\nYou can type the pipe |&gt; operator in using Shift+Ctrl/Cmd+M.\n\nenergy &lt;- energy |&gt;\n  select(\n    `Data Year`,\n    `BEUDO Category`,\n    Owner,\n    `Year Built`,\n    `Primary Property Type - Self Selected`,\n    `Total GHG Emissions (Metric Tons CO2e)`,\n    `Total GHG Emissions Intensity (kgCO2e/ft2)`,\n    Longitude,\n    Latitude\n  ) \n\nSome of the column names are surrounded by backticks (`), that’s because they include special characters or spaces, which deviate from standard naming conventions. The use of backticks is a means of preserving these unique naming attributes. Just keep typing the column names, dplyr will populate the correct names for you."
  },
  {
    "objectID": "labs/lab1.html#filter-select-a-subset-of-rows",
    "href": "labs/lab1.html#filter-select-a-subset-of-rows",
    "title": "Get started with ",
    "section": "filter: Select a subset of rows",
    "text": "filter: Select a subset of rows\nIn base R, we do this to pick observations by their values:\ndataset[dataset$place == “Boston\", ]\nIn dplyr, we do:\ndataset |&gt; filter(place == “Boston\")\nAgain, a simpler and more understandable syntax.\nNow let’s create a new dataset that only contains energy use records from MIT buildings and that are not missing the total GHG emission attribute. Take a look at how we achieve this using the following code, then proceed to insert a new code chunk in your document like the one below:\n\nmit_energy &lt;- energy |&gt; \n  filter(Owner == \"MASSACHUSETTS INSTITUTE OF TECHNOLOGY\") |&gt; \n  filter(!is.na(`Total GHG Emissions (Metric Tons CO2e)`))"
  },
  {
    "objectID": "labs/lab1.html#mutate-create-or-modify-columns",
    "href": "labs/lab1.html#mutate-create-or-modify-columns",
    "title": "Get started with ",
    "section": "mutate: create or modify columns",
    "text": "mutate: create or modify columns\nmutate allows you to modify your dataset by 1) add new columns to a data frame, or 2) modify values in existing columns. It’s commonly used to calculate or transform data by applying functions, helping you derive new values from your existing data.\nFor example, in the Owner column of our dataset, we have the full name of the institute. We can replace these long names with “MIT”.\n\nmit_energy |&gt; mutate(Owner = \"MIT\")\n\n# A tibble: 1,035 × 9\n   `Data Year` `BEUDO Category` Owner `Year Built` Primary Property Type - Sel…¹\n         &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                        \n 1        2016 Non-Residential  MIT           1990 Laboratory                   \n 2        2019 Non-Residential  MIT           1928 College/University           \n 3        2022 Residential      MIT           1963 College/University           \n 4        2017 Non-Residential  MIT           2005 College/University           \n 5        2018 Non-Residential  MIT           1916 College/University           \n 6        2021 Non-Residential  MIT           1967 College/University           \n 7        2016 Non-Residential  MIT           1982 College/University           \n 8        2021 Non-Residential  MIT           2001 College/University           \n 9        2021 Non-Residential  MIT           1980 Office                       \n10        2016 Non-Residential  MIT           1938 College/University           \n# ℹ 1,025 more rows\n# ℹ abbreviated name: ¹​`Primary Property Type - Self Selected`\n# ℹ 4 more variables: `Total GHG Emissions (Metric Tons CO2e)` &lt;dbl&gt;,\n#   `Total GHG Emissions Intensity (kgCO2e/ft2)` &lt;dbl&gt;, Longitude &lt;dbl&gt;,\n#   Latitude &lt;dbl&gt;\n\n\nYou can also use mutate to add new columns to your data that are calculated from existing columns. Here we are showing how to create a new column for building ages.\n\nmit_energy |&gt; mutate(Building_Age = 2023 - `Year Built`)\n\n# A tibble: 1,035 × 10\n   `Data Year` `BEUDO Category` Owner        `Year Built` Primary Property Typ…¹\n         &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                 \n 1        2016 Non-Residential  MASSACHUSET…         1990 Laboratory            \n 2        2019 Non-Residential  MASSACHUSET…         1928 College/University    \n 3        2022 Residential      MASSACHUSET…         1963 College/University    \n 4        2017 Non-Residential  MASSACHUSET…         2005 College/University    \n 5        2018 Non-Residential  MASSACHUSET…         1916 College/University    \n 6        2021 Non-Residential  MASSACHUSET…         1967 College/University    \n 7        2016 Non-Residential  MASSACHUSET…         1982 College/University    \n 8        2021 Non-Residential  MASSACHUSET…         2001 College/University    \n 9        2021 Non-Residential  MASSACHUSET…         1980 Office                \n10        2016 Non-Residential  MASSACHUSET…         1938 College/University    \n# ℹ 1,025 more rows\n# ℹ abbreviated name: ¹​`Primary Property Type - Self Selected`\n# ℹ 5 more variables: `Total GHG Emissions (Metric Tons CO2e)` &lt;dbl&gt;,\n#   `Total GHG Emissions Intensity (kgCO2e/ft2)` &lt;dbl&gt;, Longitude &lt;dbl&gt;,\n#   Latitude &lt;dbl&gt;, Building_Age &lt;dbl&gt;\n\n\nNote: A common point of confusion is the similarity between &lt;- (assign to) and |&gt;(pipe). In the two code chunks above, we are only displaying the results, not saving them to an object. The mit_energy data thus remains unchanged. To put it briefly:\n\nWhen to Use &lt;-: Use &lt;- to save or update an object with new values.\nWhen Not to Use &lt;-: If you only want to test and view results without modifying the object, do not use &lt;-."
  },
  {
    "objectID": "labs/lab1.html#group_by-summarise",
    "href": "labs/lab1.html#group_by-summarise",
    "title": "Get started with ",
    "section": "Group_by + Summarise",
    "text": "Group_by + Summarise\nSummarise is usually used in conjunction with group_by because the latter changes the scope from operating on the entire dataset to operating on it group-by-group. Go ahead and run the following code:\n\nmit_energy |&gt; \n  group_by(`Data Year`) |&gt; \n  summarise(count = n())\n\n# A tibble: 8 × 2\n  `Data Year` count\n        &lt;dbl&gt; &lt;int&gt;\n1        2015   130\n2        2016   135\n3        2017   130\n4        2018   136\n5        2019   113\n6        2020   116\n7        2021   139\n8        2022   136\n\n\nWe use group_by such that observations (i.e., rows) are grouped according to Data Year, which is the year when the energy record was taken. The result is then passed to summarise to generate a total number of records per year. By default, the n() function creates a new attribute (i.e., column), which we here name as “count”.  \nBelow we are using the same group_by + summarise chain to calculate the average GHG emissions of all buildings, and the average GHG emission intensity (use the column Total GHG Emissions Intensity (kgCO2e/ft2)). Pay attention to how we are giving new names to each of the new columns.\n\nmit_energy |&gt; \n  group_by(year = `Data Year`) |&gt; \n  summarise(count = n(),\n            avg_emission = mean(`Total GHG Emissions (Metric Tons CO2e)`),\n            avg_intensity = mean(`Total GHG Emissions Intensity (kgCO2e/ft2)`))\n\n# A tibble: 8 × 4\n   year count avg_emission avg_intensity\n  &lt;dbl&gt; &lt;int&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1  2015   130        1575.          13.4\n2  2016   135        1436.          13.2\n3  2017   130        1524.          13.5\n4  2018   136        1449.          13.1\n5  2019   113        1473.          12.6\n6  2020   116        1384.          10.9\n7  2021   139        1407.          11.4\n8  2022   136        1419.          11.4\n\n\n\nYour practice\nInsert a few new code chunks below this one to document your code and show your results. \n\nFrom the mit_energy dataset, create a subset of all non-residential buildings, which were built before the year 2000. (Hint: which function would you use?). How many such buildings are there?\nFrom the mit_energy dataset, compare the GHG emissions by property type (Hint: which column has that information?), and generate a table that shows the following results:\n\n\nYou can create this table mostly by modifying the last code chunk, however, there are a few small things you can experiment on:\n\nThe calculated average numbers in this table are rounded to 2 decimals, how to achieve that?\nThe table is arranged in descending order based on the “avg_emission” column, how to do that? (Hint)\n\nWe are already trying to ask questions and find hints of interesting stories from the dataset, which is what Exploratory Data Analysis (EDA) is all about. If the results so far look interesting/surprising/expected to you, write a few sentences describing what you see from the analysis.\n\nLastly, we will insert a map to complete your working document! This dataset includes “Longitude” and “Latitude” columns, which I love, because it indicates that location information is readily available and can be visualized.\nAdd the following code to your document, and you should be able to run it and see a map. (If your R says it can’t find mapview, run the line install.packages(\"mapview\"))\n\n\n#install.packages(\"mapview\")\nlibrary(mapview)\nmapview(\n  mit_energy,\n  xcol = \"Longitude\", ycol = \"Latitude\",\n  crs = 4326,\n  grid = FALSE\n)\n\n\n\n\n\n\n\nNow Save, Render your document again. You have now created a pretty, multi-media document using R!\n------\nIn this lab we have introduced how to create and develop a Quarto Document. We have also introduced some commonly-used dplyr funtions including select, filter, mutate, group_by and summarise. This is the beginning of our data wrangling and leads to the work in Week 2."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Data Science for Cities",
    "section": "",
    "text": "Urban science draws on statistics, visualization, and spatial analysis techniques to gain deeper insights into cities and actively contribute to their development. In this course, we’ll dive into the dynamic world of urban science by learning how to tell stories about cities and neighborhoods, covering a range of topics including demographic analysis, health and transportation, and using R as our primary quantitative analysis and interactive visualization tool.\n\n\n\n\n\n\n\nCourse Information\n\nSchedule: MW 9:30 - 11:00 AM, H2\nLocation: Mondays: 9-217; Wednesdays: 9-554\nCanvas Site: https://canvas.mit.edu/courses/27065"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "howto/setupr.html",
    "href": "howto/setupr.html",
    "title": "Applied Data Science for Cities",
    "section": "",
    "text": "Urban analytics draws upon statistics, visualization, and computation to better understand and ultimately shape cities. This course emphasizes telling stories about cities and neighborhoods covering a set of fundamental concepts of descriptive approaches, quantitative and spatial analysis in R, and principles of reproducible data analysis. Students learn to communicate the results of visualization and analysis for use in decision-making and policy development and to critique those processes."
  },
  {
    "objectID": "howto/setupr.html#this-website-is-under-construction-please-check-back-later-for-updates",
    "href": "howto/setupr.html#this-website-is-under-construction-please-check-back-later-for-updates",
    "title": "Applied Data Science for Cities",
    "section": "This website is under construction, please check back later for updates! 😄",
    "text": "This website is under construction, please check back later for updates! 😄"
  },
  {
    "objectID": "labs/index.html",
    "href": "labs/index.html",
    "title": "Schedule Overview",
    "section": "",
    "text": "Schedule\nW01 (Oct 21 - Oct 25):\n\nCourse Overview\nLab1: Cambridge Building Energy: R, Quarto, dplyr essentials\n\nW02 (Oct 28 - Nov 1):\n\nExploratory Data Analysis\nLab 2: Opportunity Zones: tidyverse, ggplot2 packages\n\nW03 (Nov 4 - Nov 8):\n\nSpatial Analysis; Obtain data from multiple sources\nLab 3: Walkable Environment: sf, osmdata packages\n\nW04 (Nov 11 – Nov 15):\n\nCreate interactive graphs and maps\nLab 4: Airbnb in Chicago: plotly and leaflet packages\n\nW05 (Nov 18 – Nov 22):\n\nCensus Data and Demographic Analysis\nLab 5: Neighborhood Change: tidycensus, tidyr packages\n\nW06 (Nov 25 – Nov 29):\n\nWeb Storytelling I\nLab 6: Build ShinyApp with flexdashboard\n\nW07 (Dec 2 – Dec 6):\n\nWeb Storytelling II\nWork on projects\n\nW08 (Dec 9 – Dec 11):\n\nPresentation"
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Exploratory Data Analysis with ",
    "section": "",
    "text": "This week’s Lab Exercise focuses on the dplyr package and the ggplot2 package. It also begins to engage with data visualization best practices by demonstrating how to create and interpret a variety of graphics.\nExploratory data analysis (EDA) is a phase of a larger data science workflow that emphasizes getting to know the data before rushing to analyze it. EDA typically involves the creation and interpretation of graphics in order to build familiarity and gain fundamental insights that can inform more sophisticated analyses later on. There are several overarching goals of exploratory data analysis, including:\n\nTo determine if there are any problems with your dataset.\nTo determine whether the question you are asking can be answered by the data that you have.\nTo begin formulating an answer to your question."
  },
  {
    "objectID": "labs/lab2.html#download-data-and-load-packages",
    "href": "labs/lab2.html#download-data-and-load-packages",
    "title": "Exploratory Data Analysis with ",
    "section": "Download data and load packages",
    "text": "Download data and load packages\nDownload the Lab 2 folder provided on Canvas. Initiate RStudio by double-clicking the .Rproj file.\nNow please navigate to Urban Institute’s website about Opportunity Zones, find the link “Download tract-level data on all Opportunity Zones”, and download this dataset to your “data” folder within your Lab 2 project folder.\nStart a new .qmd file and remove the template texts.\nTo stay organized, we should load packages at the beginning of our markdown document. These are the three packages we are going to use today. You may want to run install.packages() on readxl and DataExplorer if it’s the first time you use them.\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(DataExplorer)"
  },
  {
    "objectID": "labs/lab2.html#initial-data-cleaning",
    "href": "labs/lab2.html#initial-data-cleaning",
    "title": "Exploratory Data Analysis with ",
    "section": "Initial data cleaning",
    "text": "Initial data cleaning\nThe Urban Institute has coded the designated variable as either taking a value of 1 when designated, or NA when not. We can recode the NA values in DesignatedOZ for legibility. In the following code, we use the dplyr function: mutate to modify DesignatedOZ in place. We replaced the numbers with texts since the NA and 1 here have no mathematical meaning.\n\nozs &lt;- ozs |&gt;\n  mutate(DesignatedOZ = case_when(\n    DesignatedOZ == 1 ~ \"Designated\",\n    is.na(DesignatedOZ) ~ \"Not Designated\"\n  ))\n\nThis modification will make it much easier for us to make a quick count of both types of areas.\n\nozs |&gt; \n  count(DesignatedOZ) \n\n# A tibble: 2 × 2\n  DesignatedOZ       n\n  &lt;chr&gt;          &lt;int&gt;\n1 Designated      8764\n2 Not Designated 33414\n\n\nThere are a few columns (such as SE_Flag) that wont’ be very helpful for this analysis. We can select a subset of columns to work on. If there is a minus sign in front of the column names, that means to drop these specified columns.\n\nozs &lt;- ozs |&gt; \n  select(-c(dec_score, SE_Flag, pctown, Metro, Micro, NoCBSAType))\n\nOne of the characteristics tracked in the Urban Institute data is the median household income for each tract. We might question whether there’s a difference in the median household income for designated and not-designated census tracts. Let’s see if we can calculate the mean of the median household income values:\n\nmean(ozs$medhhincome)\n\n[1] NA\n\n\nIt returns NA. But it doesn’t indicate an issue with our code. The reason for this is the presence of missing values in this column. When dealing with numerical variables, NA values affect calculation results because we can’t decide if the missing values are larger or smaller than the others and we don’t know how to calculate them.\nSort the medhhincome column by clicking the little triangles appearing on the column name. Drag down to the bottom of the dataset, then you will see quite a few of NAs in the Census demographic columns.\nHow many missing values are there, and how many would be a hurdle for my analysis? It will be great to have a sense of completeness in terms of what proportion of a field actually holds data. DataExplorer is a handy tool that offers functions to quickly understand the completeness of datasets.\n\nDataExplorer::plot_missing(ozs)\n\n\n\n\nplot_missing calculates the proportion of missing values in a given variable, and makes some judgemental calls of whether the missing is significant, indicated by “Good”, “OK”, and “Bad”. (Check out the documentation by typing ?plot_missing in your console. What are the default ranges for these three categories?) Overall, most of our columns have a very small percentage of missing values (less than 1%) and would not create significant representative issues. However, when performing calculations, we need to include the na.rm = TRUE argument, indicating that we are calculating based on the available 99%.\n\nmean(ozs$medhhincome, na.rm = TRUE)\n\n[1] 42152.76\n\n\nWith that, we can calculate the average median household income for designated and not-designated census tracts using group_by + summarise.\n\nozs |&gt; \n  group_by(DesignatedOZ) |&gt; \n  summarise(\n    Tracts = n(),\n    Income = mean(medhhincome, na.rm=TRUE))\n\n# A tibble: 2 × 3\n  DesignatedOZ   Tracts Income\n  &lt;chr&gt;           &lt;int&gt;  &lt;dbl&gt;\n1 Designated       8764 33346.\n2 Not Designated  33414 44446.\n\n\nWe could summarize based on two groups - summarize first by state than by legibility - so that we have such comparisons for each state.\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE))\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 108 × 3\n# Groups:   state [57]\n   state          DesignatedOZ   Income\n   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;\n 1 Alabama        Designated     30044.\n 2 Alabama        Not Designated 36542.\n 3 Alaska         Designated     49840.\n 4 Alaska         Not Designated 54784.\n 5 American Samoa Designated       NaN \n 6 Arizona        Designated     34373.\n 7 Arizona        Not Designated 40961.\n 8 Arkansas       Designated     31254.\n 9 Arkansas       Not Designated 37814.\n10 California     Designated     36134.\n# ℹ 98 more rows\n\n\nIt might be useful for us to reshape our summary table so that there is one row for each county, with each row containing the summary value for both designated and not designated tracts.\nThe two commands pivot_wider() and pivot_longer() are useful for reshaping our data. pivot_wider() essentially adds columns to a dataset by transitioning content from rows to columns. pivot_longer() does the opposite - it makes a dataset longer by transitioning columns to rows.\nIn our case, let’s use pivot_wider() to transition our Designated and Not Designated rows into columns.\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) |&gt; \n  pivot_wider(names_from = DesignatedOZ, values_from = Income)\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 57 × 3\n# Groups:   state [57]\n   state                Designated `Not Designated`\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;\n 1 Alabama                  30044.           36542.\n 2 Alaska                   49840.           54784.\n 3 American Samoa             NaN               NA \n 4 Arizona                  34373.           40961.\n 5 Arkansas                 31254.           37814.\n 6 California               36134.           50858.\n 7 Colorado                 41138.           49601.\n 8 Connecticut              36760.           51389.\n 9 Delaware                 40971.           50143.\n10 District of Columbia     38291.           62840.\n# ℹ 47 more rows\n\n\nThat makes it easier to calculate and show the difference in income between designated and not designated tracts:\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) |&gt; \n  pivot_wider(names_from = DesignatedOZ, values_from = Income) |&gt; \n  mutate(Difference = Designated - `Not Designated`)\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 57 × 4\n# Groups:   state [57]\n   state                Designated `Not Designated` Difference\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alabama                  30044.           36542.     -6498.\n 2 Alaska                   49840.           54784.     -4944.\n 3 American Samoa             NaN               NA        NaN \n 4 Arizona                  34373.           40961.     -6588.\n 5 Arkansas                 31254.           37814.     -6560.\n 6 California               36134.           50858.    -14724.\n 7 Colorado                 41138.           49601.     -8463.\n 8 Connecticut              36760.           51389.    -14628.\n 9 Delaware                 40971.           50143.     -9172.\n10 District of Columbia     38291.           62840.    -24548.\n# ℹ 47 more rows"
  },
  {
    "objectID": "labs/lab2.html#exercise-1",
    "href": "labs/lab2.html#exercise-1",
    "title": "Exploratory Data Analysis with ",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhile we are now examining the nationwide dataset, you are going to conduct some focused analysis for Massachusetts. Please insert a new code chunk below to create a new object ozs_ma that extracts all tracts in Massachusetts. Then add some more code chunks and texts to document your responses to the following questions.\n\nIn Massachusetts, how many eligible census tracts are designated as Opportunity Zones, and how many are not designated?\n\nWhich function or approach did you use to answer this question?\n\nChoose one of the following variables: medhhincome, vacancyrate, unemprate, pctwhite, pctblack, pctHispanic, pctover64, HSorlower.\nSay that you have chosen unemprate:\n\nWhat are the ‘average unemployment rate’ for both designated and not designated tracts in Massachusetts?\nWhat is the difference in the ‘average unemployment rate’ between designated and non-designated tracts within Middlesex County?\nWhich county has the greatest disparity in ‘average unemployment rates’ between designated and non-designated tracts?"
  },
  {
    "objectID": "labs/lab2.html#distribution-of-one-variable",
    "href": "labs/lab2.html#distribution-of-one-variable",
    "title": "Exploratory Data Analysis with ",
    "section": "Distribution of one variable",
    "text": "Distribution of one variable\n\nBox Plot\nNow we are ready to create some visual representations of our data. The code below creates a boxplot to contrast the distribution of poverty rates between designated opportunity zones and undesignated zones. We are using what should now be familiar conventions to construct the graphic beginning with the ggplot function, then adding more features with the + operator and other functions listed in the package reference.\n\nggplot(data = ozs): This is the main plotting function. ozs is your dataset we use.\ngeom_boxplot(): Recall that geometric layers are called geoms. It tells R what kind of geometry you want to use visualize the data.\naes(x = DesignatedOZ, y = PovertyRate): The aes() function is where you tell ggplot which variable goes on the x axis followed by which variable goes on the y axis.\nThe third aesthetic element is fill, which indicates the filled color of the boxplot. Accordingly, we use the fill argument in the labs function to set the name of the legend.\nWe used a new function scale_y_continuous to specify y axis properties. Here we are making sure the poverty rate are labeled as percentages. If you remove this line, they will by default show as decimal numbers.\n\n\nggplot(data = ozs) +\n  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), na.rm = TRUE) + \n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Opportunity Zone Eligible Tracts\", y = \"Poverty Rate\", fill = \"Tracts\")\n\n\n\n\nBy comparing the 50th percentile (the horizontal line inside each box) we can see that tracts designated as Opportunity Zones have a higher poverty rate compared with those not designated. The heights of the boxes themselves give us an indication of how closely around the median all values in the dataset are concentrated—the degree of dispersion or spread. The vertical lines are called whiskers and extend upward and downward to the lowest values that are not candidates for outlier status. An outlier is an unusual value that could potentially influence the results of an analysis. These are indicated with dots in the boxplot.\nOutliers can be legitimate values, and require the exercise of judgment on the part of the analyst and may be removed or excluded from the analysis or imputed. There are a variety of criteria that have been offered, but you will address this question from a more statistical perspective in your other courses that introduce linear methods.\n\n\nDensity plot\nBy modifying the last code chunk, we can make a density plot to describe the distribution of poverty rate. A density plot can be understood as a smoothed version of the histogram, and provides a more direct view of of the shape and peaks in the data. The x-axis typically represents the range of values for the variable of interest, while the y-axis represents the probability density (how likely it is for the variable to take on a particular value within that range).\n\nggplot(data = ozs) +\n  geom_density(aes(x = PovertyRate, fill = DesignatedOZ), na.rm = TRUE) + \n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Poverty Rate\", fill = \"Tracts\")\n\n\n\n\nIf you have noticed - in the code above, we didn’t provide a variable that what goes to the y-axis. Where does the value “density” come from?\nMany graphs, like boxplot, plot the raw values of your dataset. But other graphs, like histograms and density plots, calculate new values to plot. Here a density takes the count of data points at discrete poverty rate levels and smooths it out into a continuous curve. Then calculated values (probability density) go to the y-axis.\n\n\nCombinations of basic graphs to create composite views\nOne of the coolest thing about ggplot is that we can plot multiple geom_ on top of each other. For instance, we can combine the two plots above, to show both visually appealing curves and essential statistics (medians, quartiles, outliers, etc.) The following code uses two geom_(Check out geom_violin for more!), and introduces several new and helpful arguments for fine-tuning the cosmetics.\n\ntrim = FALSE: If TRUE (default), trim the tails of the violins to the range of the data. If FALSE, don’t trim the tails and show the complete distribution.\nalpha = 0.5: the transparency of the plotting area.\ncoord_flip(): whether the y axis is displayed horizonally or vertically.\nlegend.position = \"none\": the position of legend (“left”, “right”, “bottom”, “top”, or two-element numeric vector), or not showing the legend (“none”).\n\n\nggplot(ozs) +\n  geom_violin(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), trim = FALSE, alpha = 0.5) +\n  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate), colour = \"black\", width = .15, alpha = 0.8) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    x = \"Opportunity Zone Eligible Tracts\",\n    y = \"Poverty Rate\",\n    title = \"Distribution of Poverty Rate\"\n  ) +\n  coord_flip() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "labs/lab2.html#exercise-2",
    "href": "labs/lab2.html#exercise-2",
    "title": "Exploratory Data Analysis with ",
    "section": "Exercise 2",
    "text": "Exercise 2\nFocus on your selected variable in Exercise 1 and your data specific to Massachusetts. Explore the distribution of your variable of interest.\n\nCreate one graphical representation that contrasts the results in designated tracts and in undesignated tracts in Massachusetts.\nInterpret the graphic you have created and include 2-3 sentences of text explanation, for example:\n\nIs it a more flat/homogeneous distribution, or a more skewed distribution in terms of fewer observations belonging to the higher-value groups? Does that align with your expectation for this variable?\nWhat can we say about the difference in demographic/economic conditions between designated and not designated census tracts in Massachusetts?\nFeel free to consult the R Graph Gallery and Aesthetic specifications for additional resources."
  },
  {
    "objectID": "labs/lab2.html#relationship-between-two-variables",
    "href": "labs/lab2.html#relationship-between-two-variables",
    "title": "Exploratory Data Analysis with ",
    "section": "Relationship between two variables",
    "text": "Relationship between two variables\n\nScatter Plot\nWe are often interested in bivariate relationships or how two variables relate to one another. Scatterplots are often used to visualize the association between two continuous variables. They can reveal much about the nature of the relationship between two variables.\nLet’s use your subset of Massachusetts data to perform this part of analysis. (We could use the nationwide dataset, but there will be over 40,000 points showing on the graph, which will not be pleasing to the eye).\nWe begin by creating a scatterplot of poverty rate and unemployment rate. Note that we used theme_bw, which is a theme template for a cleaner look.\n\nggplot(ozs_ma) +\n  geom_point(aes(x = unemprate, y = PovertyRate)) +\n  labs(x = \"Unemployment rate\",\n       y = \"Poverty rate\",\n       title = \"Poverty rate vs. unemployment rate in Opportunity Zone eligible tracts\", \n       subtitle = \"State of Massachusetts\",\n       caption = \"Source: Urban Institute (2018)\") + \n  theme_bw()\n\n\n\n\nIt is generally easy to recognize patterns in a graphical display. As we move from left to right along the x-axis (i.e., as the unemployment rate creases), the amount of poverty rate reported also increases.\nAs a complement to a scatterplot, we can use the stats::cor function to calculate the (Pearson by default, see ?cor for other options) correlation between any continuous variables in the dataset. The DataExplorer package is also designed to help us quickly understand patterns in our data. We demonstrate both in the following code.\nIf you are unfamiliar with reading a correlation matrix, the values range between -1 and 1 where:\n\n-1 indicates a perfectly negative linear correlation between two variables\n0 indicates no linear correlation between two variables\n1 indicates a perfectly positive linear correlation between two variables\n\n\nozs_ma |&gt; select(Population:medrent, pctwhite:BAorhigher) |&gt; \n  stats::cor(use = \"complete.obs\")\n\n                Population medhhincome PovertyRate  unemprate    medvalue\nPopulation    1.0000000000   0.1971310 -0.17219731 -0.1255690  0.05060663\nmedhhincome   0.1971310072   1.0000000 -0.74280330 -0.5823090  0.45672297\nPovertyRate  -0.1721973144  -0.7428033  1.00000000  0.5848120 -0.15673933\nunemprate    -0.1255690086  -0.5823090  0.58481204  1.0000000 -0.32627434\nmedvalue      0.0506066324   0.4567230 -0.15673933 -0.3262743  1.00000000\nmedrent       0.1434824928   0.6494977 -0.32058250 -0.4139894  0.60946764\npctwhite      0.0007742062   0.4334837 -0.58166274 -0.4583927  0.01479243\npctBlack      0.0305972149  -0.2081070  0.24067220  0.3002354  0.07662521\npctHispanic  -0.0610330071  -0.4470198  0.53817440  0.4107687 -0.24108925\npctAAPIalone  0.1179507879   0.1360442  0.05777953 -0.1516819  0.38403023\npctunder18    0.0075944281  -0.3886837  0.28931873  0.4263952 -0.48597184\npctover64    -0.0200934534   0.1116477 -0.40837729 -0.2236285 -0.08790793\nHSorlower    -0.0510755304  -0.6192728  0.38428550  0.5080771 -0.59138685\nBAorhigher    0.0317046620   0.5837037 -0.24483958 -0.4850706  0.71630822\n                 medrent      pctwhite    pctBlack pctHispanic pctAAPIalone\nPopulation    0.14348249  0.0007742062  0.03059721 -0.06103301   0.11795079\nmedhhincome   0.64949767  0.4334836763 -0.20810703 -0.44701977   0.13604425\nPovertyRate  -0.32058250 -0.5816627414  0.24067220  0.53817440   0.05777953\nunemprate    -0.41398938 -0.4583927470  0.30023542  0.41076874  -0.15168191\nmedvalue      0.60946764  0.0147924343  0.07662521 -0.24108925   0.38403023\nmedrent       1.00000000  0.0592656294 -0.01942961 -0.21839927   0.37309846\npctwhite      0.05926563  1.0000000000 -0.64391155 -0.72603098  -0.14608318\npctBlack     -0.01942961 -0.6439115534  1.00000000  0.05756055  -0.07150764\npctHispanic  -0.21839927 -0.7260309801  0.05756055  1.00000000  -0.16352352\npctAAPIalone  0.37309846 -0.1460831806 -0.07150764 -0.16352352   1.00000000\npctunder18   -0.47107334 -0.4866220916  0.28987714  0.52756318  -0.29072583\npctover64    -0.20439363  0.5440272257 -0.22702697 -0.42430798  -0.23991183\nHSorlower    -0.59290214 -0.4609030805  0.16871183  0.56358387  -0.25180077\nBAorhigher    0.67357448  0.3278345358 -0.19790460 -0.42390213   0.38422347\n               pctunder18    pctover64   HSorlower   BAorhigher\nPopulation    0.007594428 -0.020093453 -0.05107553  0.031704662\nmedhhincome  -0.388683691  0.111647722 -0.61927277  0.583703714\nPovertyRate   0.289318732 -0.408377288  0.38428550 -0.244839584\nunemprate     0.426395199 -0.223628488  0.50807715 -0.485070585\nmedvalue     -0.485971837 -0.087907931 -0.59138685  0.716308223\nmedrent      -0.471073339 -0.204393629 -0.59290214  0.673574479\npctwhite     -0.486622092  0.544027226 -0.46090308  0.327834536\npctBlack      0.289877141 -0.227026967  0.16871183 -0.197904602\npctHispanic   0.527563183 -0.424307981  0.56358387 -0.423902133\npctAAPIalone -0.290725828 -0.239911831 -0.25180077  0.384223470\npctunder18    1.000000000 -0.248306018  0.68045309 -0.718007353\npctover64    -0.248306018  1.000000000 -0.14789121 -0.003268322\nHSorlower     0.680453091 -0.147891209  1.00000000 -0.923184800\nBAorhigher   -0.718007353 -0.003268322 -0.92318480  1.000000000\n\n\n\nozs_ma |&gt; select(Population:medrent, pctwhite:BAorhigher) |&gt; \n  na.omit() |&gt; \n  DataExplorer::plot_correlation()\n\n\n\n\nAn additional note to the code above is that we selected several continuous variables that we want to inspect, and removed NA values (use = \"complete.obs\") so that the correlation values can be correctly calculated.\nWhat can we do if we are interested in statistical associations between categorical variables? The typical approach is to use a chi-squared test (see the chisq.test function in the stats package) in conjunction with visual tools like barcharts. We won’t delve deeply into the statistical aspect, but we will learn the useful bar plots for displaying summary statistics of categorical data.\n\n\nBar plot\nIn the following code, you can see our familiar group_by + summarise process used to calculate the average median house income by county in Massachusetts. This summarized table is then piped to ggplot() for visualization.\n\nozs_ma |&gt; \n  group_by(county, DesignatedOZ) |&gt;  \n  summarise(\n    Tracts = n(),\n    Income = mean(medhhincome, na.rm=TRUE)) \n\n# A tibble: 25 × 4\n# Groups:   county [13]\n   county            DesignatedOZ   Tracts Income\n   &lt;chr&gt;             &lt;chr&gt;           &lt;int&gt;  &lt;dbl&gt;\n 1 Barnstable County Designated          6 46717.\n 2 Barnstable County Not Designated     22 61663.\n 3 Berkshire County  Designated          6 35199 \n 4 Berkshire County  Not Designated     15 51122.\n 5 Bristol County    Designated         12 34573.\n 6 Bristol County    Not Designated     59 42035.\n 7 Dukes County      Not Designated      1 46816 \n 8 Essex County      Designated         20 41358.\n 9 Essex County      Not Designated     50 49966.\n10 Franklin County   Designated          7 41711.\n# ℹ 15 more rows"
  },
  {
    "objectID": "labs/lab2.html#exercise-3",
    "href": "labs/lab2.html#exercise-3",
    "title": "Exploratory Data Analysis with ",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nBuilding on the last code block, add ggplot() to produce a barchart that shows the summarised income of both designated tracts and undesignated tracts in each county.\nYou are going to decide what geom_ to use and what to put into the aes() .\n\n\n\nAfter you have produced your graph, take a few minutes to read this bar chart below:\n\n\nThere should be a few differences in this graph compared with what a default function would give us. How can you modify your code above to replicate the bar chart in this image? In a new code chunk, please copy and paste your last bar chart code, and try your best to address the following questions.\n\nThe bars are put side-by-side instead of stacking on top of one another. More explainations here. If you don’t want a stacked bar chart, you can use one of the three other options: “identity”, “dodge”, or “fill”.\nThe x-axis labels are titled to 45 degrees. How can I achieve this? Hint.\nThe labels on the y-axis are formatted in thousands with commas. This can be achieved by modifying the function scale_y_continuous(labels = scales::percent) we have seen before. Hint.\nLastly, the counties are not arranged alphabetically, but rather by the income values mapped to the y-axis, starting from large to small. How can I achieve this? Hint.\nPlease add the title, subtitle, x- and y-axis labels, and the data source annotation to your bar chart.\nPlease choose a theme template for your bar chart."
  },
  {
    "objectID": "labs/lab2.html#bonus-scatterplot-with-marginal-histograms",
    "href": "labs/lab2.html#bonus-scatterplot-with-marginal-histograms",
    "title": "Exploratory Data Analysis with ",
    "section": "Bonus: Scatterplot with marginal histograms",
    "text": "Bonus: Scatterplot with marginal histograms\nThis is just for fun - If you want to create more advanced statistical plots, there are ways to do that too. The following graph requires an additional package ggExtra. But the other syntax should be familiar now.\n\n#install.packages(\"ggExtra\")\np &lt;- ggplot(ozs_ma) + \n  geom_point(aes(x = pctBlack, y = PovertyRate, color = DesignatedOZ)) + \n  theme_bw()\nggExtra::ggMarginal(p, type = \"histogram\", groupFill = TRUE)"
  },
  {
    "objectID": "labs/lab4.html",
    "href": "labs/lab4.html",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "",
    "text": "Today we’re going to explore a couple of new packages and how they can be used to enhance our visualizations. We will use an example to show how to use these tools effectively:\n\nplotly and adding interactivity through ggplotly\nInteractive maps with leaflet\nIntroduce dashboards with flexdashboard\n\nIn terms of creating good and effective data analyses, mastering the ‘fundamentals’ is more important than pursuing ‘advanced’ tools. Step one is always to have a good understanding of the data you are representing. Interactivity tools contribute to improving interpretation, but they cannot replace proficiency in the subject matter.\n\n# You may need to install plotly, leaflet, flexdashboard\n\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(leaflet)\nlibrary(sf)\nlibrary(tigris)"
  },
  {
    "objectID": "labs/lab4.html#data-cleaning",
    "href": "labs/lab4.html#data-cleaning",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nIn class, we covered two important data-cleaning steps. We first removed the dollar signs from the price column to facilitate our subsequent numerical analyses. We then converted the character data in the last_review column into the date format to manage temporal-related analyses. We used the stringr package and the lubridate package, respectively.\n\nairbnb &lt;- data |&gt; \n  mutate(price = str_replace(string = price, \n                             pattern = \"\\\\$\", \n                             replacement = \"\")) |&gt; \n  mutate(price =  str_replace(price, \",\", \"\")) |&gt; \n  mutate(price = as.numeric(price))\n\n\nairbnb &lt;- airbnb |&gt; \n  mutate(last_review = ymd(last_review)) |&gt; \n  mutate(last_review_year = year(last_review),\n         last_review_month = month(last_review))\n\nAfter these two data-cleaning steps, please save a copy of this dataset to your data folder. It will make it easier for us to import it into another script shortly.\nsaveRDS(airbnb, \"data/airbnb.rds\")"
  },
  {
    "objectID": "labs/lab4.html#chart-b-median-room-price-by-type",
    "href": "labs/lab4.html#chart-b-median-room-price-by-type",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "Chart B: Median Room Price by Type",
    "text": "Chart B: Median Room Price by Type\n\ng &lt;- airbnb |&gt; \n  group_by(room_type) |&gt; \n  summarise(median_price = median(price)) |&gt; \n  ggplot() + \n    geom_col(aes(x = room_type, y = median_price), fill = \"#62A0CA\", width = 0.5) + \n  theme_bw()+\n  labs(x = \"Room Type\", y = \"Median Price\")\n  \n\nggplotly(g)"
  },
  {
    "objectID": "labs/lab4.html#chart-c-donut-chart-of-last-reviews",
    "href": "labs/lab4.html#chart-c-donut-chart-of-last-reviews",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "Chart C: Donut Chart of Last Reviews",
    "text": "Chart C: Donut Chart of Last Reviews\n\nairbnb |&gt; \n  group_by(last_review_year) |&gt; \n  summarise(count_review = n()) |&gt; \n  plot_ly() |&gt;  \n  add_pie(labels = ~last_review_year, \n          values = ~count_review,\n          hole = 0.6)"
  },
  {
    "objectID": "labs/lab4.html#work-process",
    "href": "labs/lab4.html#work-process",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "Work Process",
    "text": "Work Process\n\nBasemap\nFirst, we initiate leaflet and add a basemap. We are adding a basemap created by CartoDB. Alternatively, there are all the other web map options from ESRI, OpenStreetMap, etc.\nThe setView defines the initial center and zoom level of a map, where larger zoom values result in a more detailed view.\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) \n\n\n\n\n\n\n\nCircle markers\nThen we can add the Airbnb listings as circle markers on the map, where we can define:\n\nthe circle size (radius),\nwhether to have fill (fill=TRUE), with what color (fillColor) and transparency (fillOpacity),\nwhether to have strokes (stroke=TRUE), stroke width (weight), and with what color (color) and transparency (opacity),\n\netc., etc….\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) |&gt; \n  addCircleMarkers(data = airbnb,\n                   fill = TRUE,\n                   fillOpacity = 0.5,\n                   stroke = FALSE,\n                   radius = 1) \n\n\n\n\n\n\n\nPopup labels\nTo enable popup tooltips to display information upon user clicks, we need to define the appearance of labels using formatted text. In this text listing_popup, each line shows “item name: airbnb attribute values”. This label format is then added into addCircleMarkers as the input of the popup argument.\nThe HTML tags (&lt;br&gt; and &lt;b&gt;…&lt;b&gt;) may look unfamiliar but they suggest that this string is intended for display in an HTML context, where line breaks and bold formatting are relevant.\n\nlisting_popup &lt;-\n  paste0(airbnb$name, \"&lt;br&gt;\",\n    \"&lt;b&gt;Neighborhood: &lt;/b&gt;\", airbnb$neighborhood,\"&lt;br&gt;\",\n    \"&lt;b&gt;Room Type: &lt;/b&gt;\", airbnb$room_type, \"&lt;br&gt;\",\n    \"&lt;b&gt;Price: &lt;/b&gt;\", airbnb$price, \"&lt;br&gt;\",\n    \"&lt;b&gt;Average Rating: &lt;/b&gt;\", airbnb$review_scores_rating\n  )\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) |&gt; \n  addCircleMarkers(data = airbnb,\n                   fillOpacity = 0.5,\n                   stroke = FALSE,\n                   radius = 1,\n                   popup = listing_popup) \n\n\n\n\n\n\n\nColor\nLeaflet uses color mapping functions to assign colors to categorical variables and numeric variables, respectively. In this following line, we create a “relationship” between the categorical values in the airbnb$room_type variable and a sequential color palette RdYlGn (“red-yellow-green”).\npal &lt;- colorFactor(palette = \"RdYlGn\", domain = airbnb$room_type)\nThen this “relationship” pal is passed to two things:\n1) fillColor = ~pal(room_type). You again encounter the use of the tilde (~) symbol, indicating that this input represents a relationship on a given variable (room type).\n2) addLegend(pal = pal) so the that colors in the legend will show up accordingly.\n\npal &lt;- colorFactor(palette = \"RdYlGn\", domain = airbnb$room_type)\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) |&gt; \n  addCircleMarkers(data = airbnb,\n                   fillColor = ~pal(room_type),\n                   fillOpacity = 1,\n                   stroke = FALSE,\n                   radius = 1,\n                   popup = listing_popup) |&gt; \n  addLegend(\n    position = 'topright',\n    pal = pal,\n    values = airbnb$room_type,\n    title = \"Room Type\"\n  )\n\n\n\n\n\n\n\nPolygons\nLet’s grab a tigris place boundary for Chicago, and add it to our map:\n\noptions(tigris_use_cache=TRUE)\nchi_boundary &lt;- places(state = \"IL\") |&gt; filter(NAME == \"Chicago\")\n\nIn this additional function addPolygons, we can adjust the boundary color and fill color:\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) |&gt; \n  addCircleMarkers(data = airbnb,\n                   fillColor = ~pal(room_type),\n                   fillOpacity = 1,\n                   stroke = FALSE,\n                   radius = 1,\n                   popup = listing_popup) |&gt;\n  addPolygons(data = chi_boundary,\n              color = \"blue\",\n              fill = FALSE,\n              weight = 1) |&gt; \n  addLegend(\n    position = 'topright',\n    pal = pal,\n    values = airbnb$room_type,\n    title = \"Room Type\"\n  )\n\n\n\n\n\nWhat we have created so far already resembles Inside Airbnb’s visualization. For the last step, we will add a layer control to turn on and off layer groups as we wish.\n\n\nLayer Control\nbaseGroups: We added two more basemaps using addProviderTiles, organizing each as a group named “ESRI World Imagery,” “CartoDB Dark,” and “CartoDB Positron” correspondingly. These group names are passed to the addLayersControl for users to toggle on and off.\noverlayGroups: This argument organizes layers on top of the base map. In this case, we added a group argument in both the addCircleMarkers and addPolygons functions, giving each a name, then passed their names to addLayersControl. Similar to the case of basemaps, users can toggle on and off the points and the polygon layers with their respective names.\noptions: In this example, collapsed = TRUE means that the layers control will initially be collapsed or hidden, showing a cleaner interface.\n\nleaflet() |&gt;\n  addProviderTiles(\"Esri.WorldImagery\", group = \"ESRI World Imagery\") |&gt; \n  addProviderTiles(providers$CartoDB.DarkMatter, group = \"CartoDB Dark\") |&gt; \n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) |&gt; \n  addCircleMarkers(data = airbnb,\n                   fillColor = ~pal(room_type),\n                   fillOpacity = 1,\n                   stroke = F,\n                   radius = 1,\n                   popup = listing_popup,\n                   group = \"Airbnb Listings\") |&gt;\n  addPolygons(data = chi_boundary,\n              color = \"blue\",\n              fill = FALSE,\n              weight = 1,\n              group = \"Chicago Boundary\") |&gt; \n  addLegend(\n    position = 'topright',\n    pal = pal,\n    values = airbnb$room_type,\n    title = \"Room Type\"\n  ) |&gt; \n  addLayersControl(\n    baseGroups = c(\"ESRI World Imagery\", \"CartoDB Dark\", \"CartoDB Positron\"),\n    overlayGroups = c(\"Chicago Boundary\", \"Airbnb Listings\"),\n    options = layersControlOptions(collapsed = TRUE)\n  )"
  },
  {
    "objectID": "labs/lab4.html#chart-a-leaflet-map",
    "href": "labs/lab4.html#chart-a-leaflet-map",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "Chart A: Leaflet Map",
    "text": "Chart A: Leaflet Map\nThis is the complete code for the leaflet map we have created:\n\nlisting_popup &lt;-\n  paste0(airbnb$name, \"&lt;br&gt;\",\n    \"&lt;b&gt;Neighborhood: &lt;/b&gt;\", airbnb$neighborhood,\"&lt;br&gt;\",\n    \"&lt;b&gt;Room Type: &lt;/b&gt;\", airbnb$room_type, \"&lt;br&gt;\",\n    \"&lt;b&gt;Price: &lt;/b&gt;\", airbnb$price, \"&lt;br&gt;\",\n    \"&lt;b&gt;Average Rating: &lt;/b&gt;\", airbnb$review_scores_rating\n  )\n\npal &lt;- colorFactor(palette = \"RdYlGn\", domain = airbnb$room_type)\n\noptions(tigris_use_cache=TRUE)\nchi_boundary &lt;- places(state = \"IL\") |&gt; filter(NAME == \"Chicago\")\n\n\nleaflet() |&gt;\n  addProviderTiles(\"Esri.WorldImagery\", group = \"ESRI World Imagery\") |&gt;\n  addProviderTiles(providers$CartoDB.DarkMatter, group = \"CartoDB Dark\") |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  setView(lng = -87.636483, lat = 41.862984,  zoom = 10) |&gt; \n  addCircleMarkers(data = airbnb,\n                   fillColor = ~pal(room_type),\n                   fillOpacity = 1,\n                   stroke = F,\n                   radius = 1,\n                   popup = listing_popup,\n                   group = \"Airbnb Listings\") |&gt;\n  addPolygons(data = chi_boundary,\n              color = \"blue\",\n              fill = FALSE,\n              weight = 1,\n              group = \"Chicago Boundary\") |&gt; \n  addLegend(\n    position = 'topright',\n    pal = pal,\n    values = airbnb$room_type,\n    title = \"Room Type\"\n  ) |&gt; \n  addLayersControl(\n    baseGroups = c(\"ESRI World Imagery\", \"CartoDB Dark\", \"CartoDB Positron\"),\n    overlayGroups = c(\"Chicago Boundary\", \"Airbnb Listings\"),\n    options = layersControlOptions(collapsed = TRUE)\n  )"
  },
  {
    "objectID": "labs/lab4.html#create-your-own-dashboard",
    "href": "labs/lab4.html#create-your-own-dashboard",
    "title": "Creating Interactive Graphs and Maps with ",
    "section": "Create your own dashboard",
    "text": "Create your own dashboard\nJust below the YAML header, there is a code chuck named setup and marked include = FALSE. Here you can supply any data related to package loading and data preparation. Make sure you include here any of your scripts related to loading packages and reading data:\n\nNow you only need to identify and isolate the code that we produced today to populate the respective three chart sections. In other words, you should copy all the code we’ve worked through under the heading “Chart A: Leaflet Map”, and paste them in the blank code chunk under “Chart A”. Then copy and paste all the codes under “Chart B: Median Room Price by Type” and “Chart C: Donut Chart of Last Reviews” to the flexdashboard sections Chart B and Chart C.\nWhen you are ready, knit the document again, and a dashboard should appear!"
  },
  {
    "objectID": "labs/lab6.html",
    "href": "labs/lab6.html",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "",
    "text": "As a brief review, a ShinyApp comprises two essential components: the User Interface (UI) and the Server. The UI dictates the app’s appearance, defining the layout and visual elements, while the Server handles the underlying logic and data processing, enabling dynamic, real-time interactions.\nA ShinyApp typically starts from a three-line template:\n\n# library(shiny)\n\nui &lt;- fluidPage(\n  # *Input functions\n  # *Output functions\n)\n\nserver &lt;- function(input, output) {\n  # output$id &lt;- render*function(input$id)\n}\n\nshinyApp(ui, server)\n\nIn ui, you can define the…\n\nType of interface (e.g. fluidPage),\nStructure (panels, layout, etc.),\nComponents that acquire user inputs (choose a corresponding Input function). Each input component must have a unique ID.\nComponents that will display outputs (choose a corresponding Output function). Each output component must have a unique ID.\n\nIn server, most reactivity happens. The server works as an open, running function that takes the input and output defined and acquired from ui, and then produces the result in concert with a render function.\nThe relationship between the UI and the Server is established by shinyApp(ui, server) so that the app will react to the user input (ui) by re-rendering (server) continuously while the app is running."
  },
  {
    "objectID": "labs/lab6.html#preparation",
    "href": "labs/lab6.html#preparation",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "Preparation",
    "text": "Preparation\nLet’s copy and paste the files you used for creating your flexdashboard for lab 4 to your current working directory. This is what my current working directory looks like, it contains my Rproj. file, my flexdashboard.Rmd, and a data folder. In my data folder, I have the airbnb.rds that I used for the flexdashboard.\n\nKnit your flexdashboard and make sure it works. Suppose that you have created a two-column dashboard with one map on the left and two charts on the right. We will work from here and add reactive features."
  },
  {
    "objectID": "labs/lab6.html#customize-your-flexdashboard-structure",
    "href": "labs/lab6.html#customize-your-flexdashboard-structure",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "Customize your flexdashboard structure",
    "text": "Customize your flexdashboard structure\nYou’ll first need to modify 5 places in your flexdashboard.Rmd to restructure it to work with Shiny.\n\n\nAdd runtime: shiny to the YAML header at the top of the document. This specifies that the Shiny package will be used to handle reactive content.\nLoad the libraries. The packages you used may be different from what is shown above. But you can simply add library(shiny) to the list of packages you’ve already used in your flexdashboard.\nAdd a new code chunk {r data} where we will load and work with local data. Include the code chunk options message=FALSE, warning=FALSE, results='hide' .\nCreate a sidebar column. You can simply copy and paste a Column header and the dashed-line divider from your code. But make sure to add the attribute .sidebar. I have also changed the column width to 200 pixels.\nSlightly adjust the column width for your maps and charts. I have changed the two columns to 500 and 300 pixels, respectively. The total number of pixels of your sidebar + two columns should be 1,000."
  },
  {
    "objectID": "labs/lab6.html#load-and-prepare-your-data",
    "href": "labs/lab6.html#load-and-prepare-your-data",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "Load and prepare your data",
    "text": "Load and prepare your data\nJust like a normal .Rmd, your Shiny app code will run line by line or chunk by chunk. To keep it organized, we are dedicating one code chunk for loading libraries, and the second one for working with global data. In your code chunk {r data}, read in your airbnb data:\nairbnb &lt;- readRDS(\"data/airbnb.rds\")\nIf your flexdashboard involves downloading census geography data, the best practice is to relocate those lines of code here as well."
  },
  {
    "objectID": "labs/lab6.html#work-with-the-implicit-ui-and-server",
    "href": "labs/lab6.html#work-with-the-implicit-ui-and-server",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "Work with the implicit UI and Server",
    "text": "Work with the implicit UI and Server\nBuilding on top of a flexdashboard framework, the process of constructing our app is simplified. We don’t need to explicitly define a ui and a server - the connection between inputs and outputs happens implicitly. What it means to us is that we only need to:\n\nIn our sidebar column, directly enter input functions\nIn your Chart A-C areas, directly enter render functions\n\nYour initial structure should look like this:"
  },
  {
    "objectID": "labs/lab6.html#fill-in-your-input-functions",
    "href": "labs/lab6.html#fill-in-your-input-functions",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "Fill in your input functions",
    "text": "Fill in your input functions\nFill in the sliderInput and selectInput with their required arguments. I’m giving them an inputId of price_range and nbh_name, respectively.\n\nsliderInput(inputId = \"price_range\", label = \"Select a price range\",\n                  min = 0, max = 1000, value = c(0, 500))\nselectInput(inputId = \"nbh_name\", label = \"Select a neigborhood\",\n              choices = unique(airbnb$neighborhood))"
  },
  {
    "objectID": "labs/lab6.html#complete-your-render-functions",
    "href": "labs/lab6.html#complete-your-render-functions",
    "title": "Build ShinyApp with Flexdashboard and ",
    "section": "Complete your render functions",
    "text": "Complete your render functions\nConsider one of your Plotly charts as an example. First, wrap all the code you used to create this chart into the curly braces of renderPlotly({}).\nWhenever you choose a neighborhood, it results in the filtering of a subset from the original airbnb data. To make your original code for creating the bar chart responsive to your inputs, you will need to incorporate a few lines like the following (right after airbnb |&gt;), calling the input IDs.\n\nrenderPlotly({\n  g &lt;- airbnb |&gt; \n        filter(neighborhood == input$nbh_name, \n        price &gt;= input$price_range[1],       \n        price &lt; input$price_range[2]) |&gt;  \n    group_by(room_type) |&gt; \n    summarise(median_price = median(price)) |&gt; \n    ggplot() + \n      geom_col(aes(x = room_type, y = median_price), fill = \"#62A0CA\", width = 0.5) + \n    theme_bw()+\n    labs(x = \"Room Type\", y = \"Median Price\")+\n    theme(axis.text.x = element_text(size = 7))\n    ggplotly(g)\n})\n\nFor your Leaflet map, there are a few additional things to do. But first, wrap all your code related to creating your leaflet map into the curly braces of renderLeaflet({}).\n\nThe dataset for your map should also react to your input, requiring a similar filtering process. I’m assigning the filtered results to a new object, df_map, replacing the original airbnb object that exists at multiple places in this code chunk. Here it requires your careful decisions about where to perform replacements and where not to.\n\n\ndf_map &lt;- airbnb |&gt; \n    filter(neighborhood == input$nbh_name,\n    price &gt;= input$price_range[1],\n    price &lt; input$price_range[2])\n\n\nAdjust the setView function to zoom in on the selected neighborhood rather than the entire region. My approach is using the average longitude and latitude of the subset data.\n\n\n# Add these two lines before leaflet()\nmid_long &lt;- mean(df_map$longitude, na.rm = TRUE)\nmid_lat &lt;- mean(df_map$latitude, na.rm = TRUE)\n\n# Replace the original lat and lon which represents the center of your region\nleaflet() |&gt;\n  ...\n  setView(lng = mid_long, lat = mid_lat, zoom = 14)\n\nGive it a try! Now your Shiny dashboard should work. Save your file, then click “Run Document”. If some errors show up, that’s fine, and we will figure it out! You can find my final code here for troubleshooting."
  }
]