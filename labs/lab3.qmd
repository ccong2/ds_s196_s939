---
title: "Describe neighborhood dynamics with ![](../img/Rlogo.png){width=60px}"
subtitle: <span style="color:#2C3E50">11.S939 Applied Data Science for Cities</span>
date: "Last Updated `r Sys.Date()`"
format: html
editor: visual
---

# Overview

In this lab, we will develop a place profile to quantify the physical and environmental characteristics of a given area. Planners are usually interested in understanding and enhance improving urban environments. Our approach will involve utilizing spatial data and conducting spatial analysis.

![](../img/lab3_quantify_place.gif)

To put things into context, we will describe **the built environment conducive to pedestrians** in Boston neighborhoods. Much work in this field focuses on design guidelines that promote pedestrian friendliness. Urban factors such as the presence of walking facilities, the density and variety of businesses, the number of residents and jobs, and streetscape elements like benches, storefronts, and shade all influence the extent and nature of walkable areas (Frank et al., 2006; Owen et al., 2007; Jacobs, 1961; Lynch, 1960).

```{r label="load packages", message = FALSE, warning=FALSE}
library(sf)
library(tidyverse)
library(mapview)
library(osmdata)
library(scales)
```

For the purpose of demonstrating how to gather, combine and analyze spatial data from different sources, we are going to develop three relatively simple indicators to measure the pedestrian environment in a Boston neighborhoods: **sidewalk density**, **restaurants measured by points of interest (POI), and street trees**.

# Spatial files I/O

The `sf` package works with spatial data in vector format and read shapefiles as dataframe with a geometry column, containing the spatial vector geometry. This package incorporates a number of tools for spatial operations. Most of the functions in this package starts with prefix st\_. For example,

-   `st_read()`
-   `st_write()`
-   `st_crs()`

Many cities now have data hubs that provide a wealth of geospatial information, such as [Analyze Boston](https://data.boston.gov/). Let's navigate to the [Boston neighborhood boundaries](https://data.boston.gov/dataset/boston-neighborhood-boundaries-approximated-by-2020-census-block-groups1) page. Find the **shapefile** format, click Explore, and Go to resource. Save the zipped file to your data folder and unzip it. They are the polygons showing the boundaries of neighborhoods in Boston.

> Note: If you are interested, here is how we can unzip a file with R commands.
>
> ```{r message = FALSE, warning=FALSE, eval=FALSE}
> unzip(zipfile = "data/Boston_Neighborhood_Boundaries_approximated_by_2020_Census_Block_Groups.zip", exdir = "data", overwrite = TRUE)  
> file.remove("data/Boston_Neighborhood_Boundaries_approximated_by_2020_Census_Block_Groups.zip")
> ```

Use `st_read` in the `sf` package to read in the data. You may need to figure out the correct path on your side.

```{verbatim}
neighborhood <- st_read("data/Boston_Neighborhood_Boundaries_approximated_by_2020_Census_Block_Groups.shp")
```

```{r message = FALSE, warning=FALSE, echo=FALSE, results='hide'}
neighborhood <- st_read("../data/Boston_Neighborhood_Boundaries_approximated_by_2020_Census_Block_Groups.shp") 
```

We can make a quick plot using `geom_sf` in `ggplot` to check it out.

```{r message = FALSE, warning=FALSE}
ggplot(neighborhood)+
  geom_sf() 
```

Every time we obtain a new shapefile, it's advisable to check its *Coordinate Reference System (CRS)*. Having a consistent CRS across shapefiles ensure they can be accurately integrated.

```{r message = FALSE, warning=FALSE}
st_crs(neighborhood)$input
st_crs(neighborhood)$epsg
```

This informs us that the neighborhood shapefile is stored in a "State Plane coordinate system Massachusetts Mainland", which has an EPSG code 2249. EPSG code is a standardized shorthand for referencing each CRS. Feel free to navigate to [epsg.io](https://epsg.io/) and look around.

State Plane projections are "projected", meaning that x and y coordinates are measured in linear measurements (feet, in our case). This allows us to directly calculate areas and lengths of the shapes.

There are many columns in this dataset, but we can choose the ones we need and assign them identifiable names. Recall that modifying attributes does not affect the geometry, so even after selecting specific columns, you will still see the `geometry` attribute.

```{r}
neighborhood <- neighborhood |>    
  select(nbh_name = blockgr202, population = tot_pop_al)
```

# Area and Length calculation

In this part we will use:

-   `st_area()`
-   `st_length()` and one of the most common geoprocessing functions
-   `st_intersection()`: find the overlapping areas of two geometries.

The `neighborhood` object is a collection of polygons, with all the polygon details stored in the `geometry` attribute. While these details aren't meant for humans to read directly, machines can interpret it and perform operations. For example, we can calculate the area of each polygon.

```{r message = FALSE, warning=FALSE}
neighborhood |> mutate(nbh_area = st_area(geometry))
```

The new `nbh_area` column stores neighborhood areas in square feet. The values are "unit" objects. Although we can do basic math operations on unit objects, managing the units incurs memory overhead. It's better to transforming them to simple numeric values, and if needed, convert them to any unit required for your analysis (i.e., sq.mi., km2).

```{r message = FALSE, warning=FALSE}
neighborhood <- neighborhood |> 
  mutate(nbh_area = as.numeric(st_area(geometry))) 
```

Similarly, `st_length` calculate the length of linear features. To illustrate that, we will download a line dataset. From the front page of Analyze Boston, search for "sidewalk", you will find the [Sidewalk Centerline](https://data.boston.gov/dataset/sidewalk-centerline) shapefile. Download it to your data folder, unzip it, and then **read it into R with the name "sidewalk"**.

What CRS is this shapefile using? Does it have the same unit with the neighborhood boundary?

```{r message = FALSE, warning=FALSE, echo=FALSE, results='hide'}
sidewalk <- st_read("../data/Sidewalk_Centerline.shp")
```

`st_intersection` can find the shared part of two spatial objects. For example, you can clip out the sidewalks in Back Bay:

```{r}
st_intersection(sidewalk, neighborhood[2,]) |> 
  ggplot()+
  geom_sf()
```

The dataset resulting from `st_intersection` will include attributes from both the sidewalks and neighborhoods. This means each segment of the sidewalk will be linked to that specific neighborhood name.

If we overlay the sidewalks and the entire neighborhoods, the result will be sidewalk lines split at neighborhood boundaries, with each segment labeled with the neighborhood it falls within.

```{r message = FALSE, warning=FALSE}
sidewalk_data <- 
  st_intersection(sidewalk, neighborhood)
```

Check the results by clicking the `sidewalk_data` in the Environment panel, or equivalently, using `View(sidewalk_data)` .

Once you have the intersected dataset, use `st_length` to calculate the length of each sidewalk segment.

```{r message = FALSE, warning=FALSE}
sidewalk_data <- sidewalk_data |> 
  mutate(length = as.numeric(st_length(geometry))) 
```

Then, you can use `group_by` and `summarize` to calculate the total sidewalk length within each neighborhood:

```{r}
sidewalk_data <- sidewalk_data |> 
  group_by(nbh_name) |> 
  summarise(sidewalk_length = sum(length)) 
```

Check our result by clicking the `sidewalk_data` in your Environment panel. You should now see the total sidewalk length for each neighborhood.

# Obtain and process OSM data

To measure amenities, we are going to download points of interest (POI) from OpenStreetMap (OSM). By allowing anyone to contribute, OSM enables the real-time evolution of its database and offers convenient options for downloading data through its free [Overpass API](https://overpass-turbo.eu/#). In this lab, we will use the [`osmdata` R package](https://cran.r-project.org/web/packages/osmdata/vignettes/osmdata.html), which simplifies download queries without much understanding of the overpass query syntax.

In order to obtain data from OSM, you will need to specify:

-   a bounding box
-   key-value pairs

### The bounding box

A bounding box is like a window of where you want to clip a piece of map. It can be defined by manually specifying two longitude-latitude pairs.

```{r message = FALSE, warning=FALSE}
# (lon, lat) of Lower left and Upper right corners  
bbox = c(-71.188, 42.238, -70.924, 42.393)
```

### The key-value pairs

An overpass query `opq` starts with engaging with the bounding box like this:

`q <- opq(bbox)`

Following the initial `opq(bbox)` call, we will build queries by adding one or more features, which are specified in terms of *key-value pairs*.

Here is [a complete list of key-value pairs on OSM](https://wiki.openstreetmap.org/wiki/Map_Features), in which values can be understood as specific types of places, and keys are their categories. These are the keywords you can use when downloading OSM data.

For example, restaurants are categorized in OSM under `key=amenity`, and `value=restaurant`. So a query of all restaurants within the boundary box of Boston can be constructed as follows:

```{r message = FALSE, warning=FALSE}
restaurant <- opq(bbox)|>   
  add_osm_feature(key = "amenity", value = "restaurant") |>  
  osmdata_sf() 
```

The retrieved OSM object is a huge list that includes numerous attributes; What we need is an `sf` object named `osm_points` nested in this list. Let's extract `osm_ponits`, then select only the name (and the attached geometry) of this object:

```{r message = FALSE, warning=FALSE}
restaurant <- restaurant$osm_points |> select(name)
```

Let's make a quick plot using `mapview`. Once you have the following map, you can click the Zoom button and select OpenStreetMap, so that you can zoom in to your familiar places for a detailed view. Most of the restaurants seem to be there.

```{r message = FALSE, warning=FALSE}
mapview(restaurant,
        legend = FALSE)
```

Check its CRS. If we want to associate the downloaded OSM file with the neighborhood shapefile, they need to have the same CRS. If not, use `st_transform()`.

```{r}
restaurant <- restaurant |> 
  st_transform(2249)
```

You could repeat this download - extract - transform process to obtain more OSM data such as grocery stores, fast food places, etc. to make a more comprehensive amenity. Now for time purspose we are only doing restaurants.

## Calculate the number of POIs by neighborhood

We have a point shapefile and a polygon shapefile, and now we want to count the number of points in each neighborhood. As you might have guessed, we'll use `st_intersection` again.

```{r}
count_restaurants <- 
  st_intersection(restaurant, neighborhood) |> 
  group_by(nbh_name) |> 
  summarise(restaurant = n())
```

# Calculate buffers

For our last variable of street trees, we can use the tree canopy data available in Boston. We have a visualization which is this. The data is [Treekeeper Street Trees](https://data.boston.gov/dataset/treekeeper-street-trees) on Analyze Boston. Download, read the shapefile.

You know what to do. Check its CRS, browse the attributes, is this points or polygon? Again, how many street trees in each neighborhood. what do you do? Write a data, store the count of trees in each neighborhood in a variable called `count_trees`.

```{r echo=FALSE, results='hide'}
tree <- st_read("../data/Treekeeper_Street_Trees.shp") |> 
  st_transform(2249)
```

```{r}
tree_data <- st_buffer(tree, dist = tree$dbh/2)
```

Then calculate the total area of canopy

```{r}
tree_data <- st_intersection(tree_data, neighborhood) |> 
  mutate(area = as.numeric(st_area(geometry))) |> 
  group_by(nbh_name) |> 
  summarize(canopy_area = sum(area))
```

# Assemble results

`left_join`

After working on the three dimensions, for each neighborhood, we now have:

-   Total sidewalk length in feet
-   Number of POIs for restaurants
-   Total area of street tree canopy in square feet

To make comparible metrics, we will "normalize" the raw data by calculating:

-   Sidewalk density: total sidewalk length divided by neighborhood area (ft/sq.ft)
-   POI per capita: total restaurant POIs divided by neighborhood population
-   Street tree coverage: total tree canopy area divided by neighborhood area (sq.ft/sq.ft)

To implement that, we will first combine our result with the orginal neighborhood dataset to get access to the total area and population.

This is not spatial join, this is just join datasets for numerical calculation, we want to only have the neighborhood boundary. so for the sidewalks, points, canopies, we need to drop the geometry and only contain attributes, but this has to be done explicitly by

```{r}
# Perform a left join to merge neighborhood data with sidewalk attributes after dropping the geometry column
result <- left_join(neighborhood, 
                    st_drop_geometry(sidewalk_data), 
                    by = "nbh_name")
```

<!-- Repeat -->

<!-- ```{r} -->

<!-- result <- -->

<!--   left_join(result, -->

<!--             st_drop_geometry(count_restaurants), by = "nbh_name")  -->

<!-- result <- -->

<!--   left_join(result, -->

<!--             st_drop_geometry(tree_data), by = "nbh_name") -->

<!-- ``` -->

<!-- Check the "result" variable, we now have one dataset that contains everything! -->

<!-- By observing it you'll notice: the tree coverage data for Harbor Island is not recorded. the population for Harbor Island is also not recorded. As we can't find them in the dataset we downloaded, we can choose to remove it and focus only on the geography cropped to the coastline. -->

<!-- ```{r} -->

<!-- result <- result |> filter(nbh_name != "Harbor Islands") -->

<!-- ``` -->

<!-- Then the normalization process can be done with a series of `mutate` functions. -->

<!-- ```{r} -->

<!-- result <- result |>  -->

<!--   mutate(sidewalk_density = sidewalk_length/nbh_area, -->

<!--          poi_density = (restaurant+fastfood+grocery)/population, -->

<!--          tree_coverage = canopy_area/nbh_area) -->

<!-- ``` -->

<!-- Finally, Remove intermediary variables in the working environment: -->

<!-- ```{r message = FALSE, warning=FALSE} -->

<!-- rm(list=setdiff(ls(), "result")) -->

<!-- ``` -->

<!-- # Present our result -->

<!-- use gt to make a nice table -->

<!-- ```{r message = FALSE, warning=FALSE} -->

<!-- # Rescore the sub-dimensional indices to 0-100 as well -->

<!-- score <- -->

<!--   score |> -->

<!--   mutate_at(vars(pop_density, sidewalk_coverage, poi_density), -->

<!--     ~rescale(., to = c(0, 100))) |>  -->

<!--   st_drop_geometry() -->

<!-- library(gt) -->

<!-- score|>  -->

<!--   modify_if(~is.numeric(.), ~round(., 2)) |>  -->

<!--   gt() |>  -->

<!--   tab_style( -->

<!--     locations = cells_body(columns = nbh_name), -->

<!--     style = cell_text(weight = "bold") -->

<!--   ) |> -->

<!--   opt_interactive( -->

<!--     use_compact_mode = TRUE, -->

<!--     use_text_wrapping = FALSE -->

<!--   ) -->

<!-- ``` -->

<!-- Or, we can make some [radar charts](https://r-graph-gallery.com/143-spider-chart-with-saveral-individuals.html): -->

<!-- ```{r message = FALSE, warning=FALSE} -->

<!-- nbh = "Downtown" -->

<!-- # The radar chart requires only value columns -->

<!-- temp <- score |>  -->

<!--   filter(nbh_name == nbh)|>  -->

<!--   select(pop_density, sidewalk_coverage, poi_density) -->

<!-- # I also have to manually add 2 new row: the max and min of each indicator -->

<!-- temp <- rbind(rep(100, 3), rep(0, 3), temp)  -->

<!-- library(fmsb) -->

<!-- radarchart(temp, title = nbh) -->

<!-- ``` -->

<!-- # Exercise -->

<!-- This exercise will be a self-guided mini research to evaluate the **public transportation service (supply)** of selected Boston neighborhoods. You will define 3-4 indicators that describe existing public transportation services, formulate your analysis strategy, calculate the indicators, then focus on two neighborhoods in Boston to compare your results and evaluate the public transportation supply in your study areas. -->

<!-- You can describe public transportation service by number of bus and rail stops, number of routes, length of bike routes and sidewalks, etc. You can download the datasets you need from Boston websites or OSM. The primary purpose of this exercise is to practice spatial analysis in R. You should operationalize the metrics in a manageable way and specify indicators that work for you. -->

<!-- # Work Product -->

<!-- Please document your work process and results in a new Quarto Document, and **upload your .qmd file and rendered HTML file to Canvas** **by the end of day, Tuesday, Dec 5.** -->

<!-- A quick tip: if you include `self_contained = TRUE` in your YAML header, you won't lose the pictures of your html file. -->

<!-- ![](/img/lab3-html.PNG) -->
