{
  "hash": "3081617a9a6be086325f6e8b34aa6e0c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploratory Data Analysis with ![](../img/Rlogo.png){width=60px}\"\nsubtitle: <span style=\"color:#2C3E50\">11.S939 Applied Data Science for Cities</span>\ndate: \"Last Updated 2024-08-29\"\nformat: html\neditor: visual\n---\n\n\n# Overview\n\nThis week's Lab Exercise focuses on the [dplyr](https://dplyr.tidyverse.org/index.html) package and the [ggplot2](https://ggplot2.tidyverse.org) package. It also begins to engage with data visualization best practices by demonstrating how to create and interpret a variety of graphics.\n\n**Exploratory data analysis (EDA)** is a phase of a larger data science workflow that emphasizes getting to know the data before rushing to analyze it. EDA typically involves the creation and interpretation of **graphics** in order to build familiarity and gain fundamental insights that can inform more sophisticated analyses later on. There are several overarching goals of exploratory data analysis, including:\n\n1.  To determine if there are any problems with your dataset.\n2.  To determine whether the question you are asking can be answered by the data that you have.\n3.  To begin formulating an answer to your question.\n\n# Our study topic today\n\nIn the 2017 [Tax Cuts and Jobs Act](https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.pdf), a new federal incentive was introduced to encourage investment in low-income and undercapitalized communities. States were given the chance to select specific census tracts as Opportunity Zones, where investors could enjoy tax benefits for their eligible investments. Although, there's been [a lot of curiosity](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones) among practitioners and researchers regarding how effective the program is and whether the designations made by governors were successful.\n\nIf you are interested in the locations of these Opportunity Zones, you can check out [this map](https://www.arcgis.com/apps/View/index.html?appid=77f3cad12b6c4bffb816332544f04542). The brown geometries reflected on the map are [census tracts](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_13), which are statistical subdivisions of a county for collecting demographic and socioeconomic information about inhabitants. Find a familiar place for you, and see which areas have been designated as Opportunity Zones.\n\n## Download data and load packages\n\nDownload the Lab 2 folder provided on Canvas. Initiate RStudio by double-clicking the .Rproj file.\n\nNow please navigate to Urban Institute's website about [Opportunity Zones](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones), find the link **\"Download tract-level data on all Opportunity Zones\"**, and **download this dataset** to your \"data\" folder within your Lab 2 project folder.\n\nStart a new .qmd file and remove the template texts.\n\nTo stay organized, we should load packages at the beginning of our markdown document. These are the three packages we are going to use today. *You may want to run `install.packages()` on `readxl` and `DataExplorer` if it's the first time you use them.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(DataExplorer)\n```\n:::\n\n\n# Read and examine our data\n\nThe file we've downloaded is in the Microsoft Excel \".xlsx\" format. But it's not a problem at all. We can use `read_xlsx` from the `readxl` package to read these files.\n\n`ozs <- read_xlsx(\"data/urbaninstitute_tractlevelozanalysis_update01142021.xlsx\")`\n\n\n\n\n\nIn the \"Environment\" panel on the top-right of your R interface, you should see the new object `ozs`. **Click it to preview its content**. (Alternatively, you can preview it by typing `View(ozs)` in your console).\n\nThis data lists tracts nationwide that are eligible to be designated as Opportunity Zones, whether they have been designated as Opportunity Zones or not, along with essential Census demographic data that describe these tracts. You can also see this dataset has 42,178 observations (rows) and 27 variables (columns).\n\nHere are the column definitions:\n\n-   **geoid**: combined state, county, tract FIPS (Federal Information Processing Standards) code this is a unique identification number for each census tract. If it is the first time you heard of tracts, they are sub-areas of a county defined for the purpose of taking a census.\n-   **state**: the name of the state\n-   **county**: the county name\n-   **Designated**: 1 when an eligible tract was designated as an opportunity zone, and NA where the tract was not designated.\n-   **Type**: category for OZ designation\n-   **Population**: total population of the tract\n-   **PovertyRate**: poverty rate\n-   **medhhincome**: median household income\n-   **medrent**: median gross rent (per month)\n-   **medvalue:** median house value\n-   **vacancyrate**: residential vacancy rate\n-   **unemprate:** unemployment rate\n-   **pctwhite**: White non-Hispanic population (%)\n-   **pctblack**: Black non-Hispanic population (%)\n-   **pctHispanic**: Hispanic and Latino population (%)\n-   **Metro**: tract in a metropolitan area\n\n------------------------------------------------------------------------\n\nWith all the data compiled, what this dataset might be able to tell us? For example, here are something I'm interested to know:\n\n-   How many of these eligible census tracts are designated as Opportunity Zones, and how many are not designated? What is the situation at the federal, state, and county levels?\n-   Are there any distinguishable differences in economic conditions between designated and not designated census tracts? Differences in terms of poverty rate, vacancy rate, median household income, demographics, etc.\n\n## Initial data cleaning\n\nThe Urban Institute has coded the designated variable as either taking a value of 1 when designated, or *NA* when not. We can recode the *NA* values in `DesignatedOZ` for legibility. In the following code, we use the `dplyr` function: `mutate` to modify `DesignatedOZ` in place. We replaced the numbers with texts since the *NA* and 1 here have no mathematical meaning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs <- ozs |>\n  mutate(DesignatedOZ = case_when(\n    DesignatedOZ == 1 ~ \"Designated\",\n    is.na(DesignatedOZ) ~ \"Not Designated\"\n  ))\n```\n:::\n\n\nThis modification will make it much easier for us to make a quick count of both types of areas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs |> \n  count(DesignatedOZ) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  DesignatedOZ       n\n  <chr>          <int>\n1 Designated      8764\n2 Not Designated 33414\n```\n\n\n:::\n:::\n\n\nThere are a few columns (such as `SE_Flag`) that wont' be very helpful for this analysis. We can `select` a subset of columns to work on. If there is a minus sign in front of the column names, that means to drop these specified columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs <- ozs |> \n  select(-c(dec_score, SE_Flag, pctown, Metro, Micro, NoCBSAType))\n```\n:::\n\n\nOne of the characteristics tracked in the Urban Institute data is the median household income for each tract. We might question whether there's a difference in the median household income for designated and not-designated census tracts. Let's see if we can calculate the mean of the median household income values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(ozs$medhhincome)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] NA\n```\n\n\n:::\n:::\n\n\nIt returns *NA*. But it doesn't indicate an issue with our code. The reason for this is the presence of missing values in this column. When dealing with numerical variables, *NA* values affect calculation results because we can't decide if the missing values are larger or smaller than the others and we don't know how to calculate them.\n\nSort the `medhhincome` column by clicking the little triangles appearing on the column name. Drag down to the bottom of the dataset, then you will see quite a few of *NA*s in the Census demographic columns.\n\nHow many missing values are there, and how many would be a hurdle for my analysis? It will be great to have a sense of completeness in terms of what proportion of a field actually holds data. `DataExplorer` is a handy tool that offers functions to quickly understand the completeness of datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDataExplorer::plot_missing(ozs)\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/missingvalues-1.png){width=672}\n:::\n:::\n\n\n`plot_missing` calculates the proportion of missing values in a given variable, and makes some judgemental calls of whether the missing is significant, indicated by \"Good\", \"OK\", and \"Bad\". (Check out the documentation by typing `?plot_missing` in your console. What are the default ranges for these three categories?) Overall, most of our columns have a very small percentage of missing values (less than 1%) and would not create significant representative issues. However, when performing calculations, we need to include the `na.rm = TRUE` argument, indicating that we are calculating based on the available 99%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(ozs$medhhincome, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 42152.76\n```\n\n\n:::\n:::\n\n\nWith that, we can calculate the average median household income for designated and not-designated census tracts using `group_by` + `summarise`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs |> \n  group_by(DesignatedOZ) |> \n  summarise(\n    Tracts = n(),\n    Income = mean(medhhincome, na.rm=TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  DesignatedOZ   Tracts Income\n  <chr>           <int>  <dbl>\n1 Designated       8764 33346.\n2 Not Designated  33414 44446.\n```\n\n\n:::\n:::\n\n\nWe could summarize based on two groups - summarize first by state than by legibility - so that we have such comparisons for each state.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs |> \n  group_by(state, DesignatedOZ) |> \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 108 × 3\n# Groups:   state [57]\n   state          DesignatedOZ   Income\n   <chr>          <chr>           <dbl>\n 1 Alabama        Designated     30044.\n 2 Alabama        Not Designated 36542.\n 3 Alaska         Designated     49840.\n 4 Alaska         Not Designated 54784.\n 5 American Samoa Designated       NaN \n 6 Arizona        Designated     34373.\n 7 Arizona        Not Designated 40961.\n 8 Arkansas       Designated     31254.\n 9 Arkansas       Not Designated 37814.\n10 California     Designated     36134.\n# ℹ 98 more rows\n```\n\n\n:::\n:::\n\n\nIt might be useful for us to reshape our summary table so that there is one row for each county, with each row containing the summary value for both designated and not designated tracts.\n\nThe two commands `pivot_wider()` and `pivot_longer()` are useful for reshaping our data. `pivot_wider()` essentially adds columns to a dataset by transitioning content from rows to columns. `pivot_longer()` does the opposite - it makes a dataset longer by transitioning columns to rows.\n\nIn our case, let's use `pivot_wider()` to transition our Designated and Not Designated rows into columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs |> \n  group_by(state, DesignatedOZ) |> \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) |> \n  pivot_wider(names_from = DesignatedOZ, values_from = Income)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 57 × 3\n# Groups:   state [57]\n   state                Designated `Not Designated`\n   <chr>                     <dbl>            <dbl>\n 1 Alabama                  30044.           36542.\n 2 Alaska                   49840.           54784.\n 3 American Samoa             NaN               NA \n 4 Arizona                  34373.           40961.\n 5 Arkansas                 31254.           37814.\n 6 California               36134.           50858.\n 7 Colorado                 41138.           49601.\n 8 Connecticut              36760.           51389.\n 9 Delaware                 40971.           50143.\n10 District of Columbia     38291.           62840.\n# ℹ 47 more rows\n```\n\n\n:::\n:::\n\n\nThat makes it easier to calculate and show the difference in income between designated and not designated tracts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs |> \n  group_by(state, DesignatedOZ) |> \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) |> \n  pivot_wider(names_from = DesignatedOZ, values_from = Income) |> \n  mutate(Difference = Designated - `Not Designated`)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 57 × 4\n# Groups:   state [57]\n   state                Designated `Not Designated` Difference\n   <chr>                     <dbl>            <dbl>      <dbl>\n 1 Alabama                  30044.           36542.     -6498.\n 2 Alaska                   49840.           54784.     -4944.\n 3 American Samoa             NaN               NA        NaN \n 4 Arizona                  34373.           40961.     -6588.\n 5 Arkansas                 31254.           37814.     -6560.\n 6 California               36134.           50858.    -14724.\n 7 Colorado                 41138.           49601.     -8463.\n 8 Connecticut              36760.           51389.    -14628.\n 9 Delaware                 40971.           50143.     -9172.\n10 District of Columbia     38291.           62840.    -24548.\n# ℹ 47 more rows\n```\n\n\n:::\n:::\n\n\n## Exercise 1\n\nWhile we are now examining the nationwide dataset, you are going to conduct some focused analysis for Massachusetts. Please **insert a new code chunk below to create a new object `ozs_ma` that extracts all tracts in Massachusetts**. Then add some more code chunks and texts to document your responses to the following questions.\n\n1.  In Massachusetts, how many eligible census tracts are designated as Opportunity Zones, and how many are not designated?\n\n    -   Which function or approach did you use to answer this question?\n\n2.  Choose **one of** the following variables: `medhhincome`, `vacancyrate`, `unemprate`, `pctwhite`, `pctblack`, `pctHispanic`, `pctover64`, `HSorlower`.\n\n    Say that you have chosen `unemprate`:\n\n    -   What are the 'average unemployment rate' for both designated and not designated tracts in **Massachusetts**?\n    -   What is the **difference** in the 'average unemployment rate' between designated and non-designated tracts within **Middlesex County**?\n    -   **Which county** has the greatest disparity in 'average unemployment rates' between designated and non-designated tracts?\n\n# Generate Diagnostic Graphs\n\n## Distribution of one variable\n\n### Box Plot\n\nNow we are ready to create some visual representations of our data. The code below creates a **boxplot** to contrast the distribution of poverty rates between designated opportunity zones and undesignated zones. We are using what should now be familiar conventions to construct the graphic beginning with the `ggplot` function, then adding more features with the `+` operator and other functions [listed in the package reference](https://ggplot2.tidyverse.org/reference/index.html).\n\n-   `ggplot(data = ozs)`: This is the main plotting function. `ozs` is your dataset we use.\n-   `geom_boxplot()`: Recall that geometric layers are called **geoms**. It tells R what kind of geometry you want to use visualize the data.\n-   `aes(x = DesignatedOZ, y = PovertyRate)`: The `aes()` function is where you tell `ggplot` which variable goes on the x axis followed by which variable goes on the y axis.\n-   The third aesthetic element is `fill`, which indicates the filled color of the boxplot. Accordingly, we use the `fill` argument in the `labs` function to set the name of the legend.\n-   We used a new function `scale_y_continuous` to specify y axis properties. Here we are making sure the poverty rate are labeled as **percentages**. If you remove this line, they will by default show as decimal numbers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = ozs) +\n  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), na.rm = TRUE) + \n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Opportunity Zone Eligible Tracts\", y = \"Poverty Rate\", fill = \"Tracts\")\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/boxplot-1.png){width=672}\n:::\n:::\n\n\nBy comparing *the 50th percentile* (the horizontal line inside each box) we can see that tracts designated as Opportunity Zones have a higher poverty rate compared with those not designated. The *heights* of the boxes themselves give us an indication of how closely around the median all values in the dataset are concentrated---the degree of dispersion or spread. The *vertical lines* are called whiskers and extend upward and downward to the lowest values that are not candidates for outlier status. An *outlier* is an unusual value that could potentially influence the results of an analysis. These are indicated with dots in the boxplot.\n\nOutliers can be legitimate values, and require the exercise of judgment on the part of the analyst and may be removed or excluded from the analysis or imputed. There are a variety of criteria that have been offered, but you will address this question from a more statistical perspective in your other courses that introduce linear methods.\n\n### Density plot\n\nBy modifying the last code chunk, we can make a **density plot** to describe the distribution of poverty rate. A density plot can be understood as a smoothed version of the histogram, and provides a more direct view of of the shape and peaks in the data. The x-axis typically represents the range of values for the variable of interest, while the y-axis represents the probability density (how likely it is for the variable to take on a particular value within that range).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = ozs) +\n  geom_density(aes(x = PovertyRate, fill = DesignatedOZ), na.rm = TRUE) + \n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Poverty Rate\", fill = \"Tracts\")\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/densityplot-1.png){width=672}\n:::\n:::\n\n\nIf you have noticed - in the code above, we didn't provide a variable that what goes to the y-axis. Where does the value \"density\" come from?\n\nMany graphs, like boxplot, plot the raw values of your dataset. But other graphs, like histograms and density plots, calculate new values to plot. Here a density takes the count of data points at discrete poverty rate levels and smooths it out into a continuous curve. Then calculated values (probability density) go to the y-axis.\n\n### Combinations of basic graphs to create composite views\n\nOne of the coolest thing about `ggplot` is that we can plot multiple `geom_` on top of each other. For instance, we can combine the two plots above, to show both visually appealing curves and essential statistics (medians, quartiles, outliers, etc.) The following code uses two `geom_`([Check out `geom_violin` for more](https://ggplot2.tidyverse.org/reference/geom_violin.html#:~:text=A%20violin%20plot%20is%20a,same%20way%20as%20a%20boxplot.)!), and introduces several new and helpful arguments for fine-tuning the cosmetics.\n\n-   `trim = FALSE`: If TRUE (default), trim the tails of the violins to the range of the data. If FALSE, don't trim the tails and show the complete distribution.\n-   `alpha = 0.5`: the transparency of the plotting area.\n-   `coord_flip()`: whether the y axis is displayed horizonally or vertically.\n-   `legend.position = \"none\"`: the position of legend (\"left\", \"right\", \"bottom\", \"top\", or two-element numeric vector), or not showing the legend (\"none\").\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ozs) +\n  geom_violin(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), trim = FALSE, alpha = 0.5) +\n  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate), colour = \"black\", width = .15, alpha = 0.8) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    x = \"Opportunity Zone Eligible Tracts\",\n    y = \"Poverty Rate\",\n    title = \"Distribution of Poverty Rate\"\n  ) +\n  coord_flip() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/extra-1-1.png){width=672}\n:::\n:::\n\n\n## Exercise 2\n\nFocus on your selected variable in Exercise 1 and your data specific to Massachusetts. Explore the distribution of your variable of interest.\n\n1.  Create one graphical representation that contrasts the results in designated tracts and in undesignated tracts in Massachusetts.\n2.  Interpret the graphic you have created and include 2-3 sentences of text explanation, for example:\n    -   Is it a more flat/homogeneous distribution, or a more skewed distribution in terms of fewer observations belonging to the higher-value groups? Does that align with your expectation for this variable?\n\n    -   What can we say about the difference in demographic/economic conditions between designated and not designated census tracts in Massachusetts?\n\n    -   Feel free to consult the [R Graph Gallery](#0) and [Aesthetic specifications](https://ggplot2.tidyverse.org/articles/ggplot2-specs.html) for additional resources.\n\n## Relationship between two variables\n\n### Scatter Plot\n\nWe are often interested in bivariate relationships or how two variables relate to one another. **Scatterplots** are often used to visualize the association between **two** **continuous variables**. They can reveal much about the [nature of the relationship](https://www.jmp.com/en_hk/statistics-knowledge-portal/exploratory-data-analysis/scatter-plot.html) between two variables.\n\nLet's use your subset of **Massachusetts data** to perform this part of analysis. (We could use the nationwide dataset, but there will be over 40,000 points showing on the graph, which will not be pleasing to the eye).\n\n\n::: {.cell}\n\n:::\n\n\nWe begin by creating a scatterplot of poverty rate and unemployment rate. Note that we used `theme_bw`, which is a [`theme` template](https://ggplot2.tidyverse.org/reference/ggtheme.html) for a cleaner look.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ozs_ma) +\n  geom_point(aes(x = unemprate, y = PovertyRate)) +\n  labs(x = \"Unemployment rate\",\n       y = \"Poverty rate\",\n       title = \"Poverty rate vs. unemployment rate in Opportunity Zone eligible tracts\", \n       subtitle = \"State of Massachusetts\",\n       caption = \"Source: Urban Institute (2018)\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/Scatterplot-1.png){width=672}\n:::\n:::\n\n\nIt is generally easy to recognize patterns in a graphical display. As we move from left to right along the x-axis (i.e., as the unemployment rate creases), the amount of poverty rate reported also increases.\n\nAs a complement to a scatterplot, we can use the `stats::cor` function to calculate the (Pearson by default, see `?cor` for other options) **correlation** between any continuous variables in the dataset. The `DataExplorer` package is also designed to help us quickly understand patterns in our data. We demonstrate both in the following code.\n\nIf you are unfamiliar with reading a correlation matrix, the values range between -1 and 1 where:\n\n-   -1 indicates a perfectly negative linear correlation between two variables\n-   0 indicates no linear correlation between two variables\n-   1 indicates a perfectly positive linear correlation between two variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma |> select(Population:medrent, pctwhite:BAorhigher) |> \n  stats::cor(use = \"complete.obs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                Population medhhincome PovertyRate  unemprate    medvalue\nPopulation    1.0000000000   0.1971310 -0.17219731 -0.1255690  0.05060663\nmedhhincome   0.1971310072   1.0000000 -0.74280330 -0.5823090  0.45672297\nPovertyRate  -0.1721973144  -0.7428033  1.00000000  0.5848120 -0.15673933\nunemprate    -0.1255690086  -0.5823090  0.58481204  1.0000000 -0.32627434\nmedvalue      0.0506066324   0.4567230 -0.15673933 -0.3262743  1.00000000\nmedrent       0.1434824928   0.6494977 -0.32058250 -0.4139894  0.60946764\npctwhite      0.0007742062   0.4334837 -0.58166274 -0.4583927  0.01479243\npctBlack      0.0305972149  -0.2081070  0.24067220  0.3002354  0.07662521\npctHispanic  -0.0610330071  -0.4470198  0.53817440  0.4107687 -0.24108925\npctAAPIalone  0.1179507879   0.1360442  0.05777953 -0.1516819  0.38403023\npctunder18    0.0075944281  -0.3886837  0.28931873  0.4263952 -0.48597184\npctover64    -0.0200934534   0.1116477 -0.40837729 -0.2236285 -0.08790793\nHSorlower    -0.0510755304  -0.6192728  0.38428550  0.5080771 -0.59138685\nBAorhigher    0.0317046620   0.5837037 -0.24483958 -0.4850706  0.71630822\n                 medrent      pctwhite    pctBlack pctHispanic pctAAPIalone\nPopulation    0.14348249  0.0007742062  0.03059721 -0.06103301   0.11795079\nmedhhincome   0.64949767  0.4334836763 -0.20810703 -0.44701977   0.13604425\nPovertyRate  -0.32058250 -0.5816627414  0.24067220  0.53817440   0.05777953\nunemprate    -0.41398938 -0.4583927470  0.30023542  0.41076874  -0.15168191\nmedvalue      0.60946764  0.0147924343  0.07662521 -0.24108925   0.38403023\nmedrent       1.00000000  0.0592656294 -0.01942961 -0.21839927   0.37309846\npctwhite      0.05926563  1.0000000000 -0.64391155 -0.72603098  -0.14608318\npctBlack     -0.01942961 -0.6439115534  1.00000000  0.05756055  -0.07150764\npctHispanic  -0.21839927 -0.7260309801  0.05756055  1.00000000  -0.16352352\npctAAPIalone  0.37309846 -0.1460831806 -0.07150764 -0.16352352   1.00000000\npctunder18   -0.47107334 -0.4866220916  0.28987714  0.52756318  -0.29072583\npctover64    -0.20439363  0.5440272257 -0.22702697 -0.42430798  -0.23991183\nHSorlower    -0.59290214 -0.4609030805  0.16871183  0.56358387  -0.25180077\nBAorhigher    0.67357448  0.3278345358 -0.19790460 -0.42390213   0.38422347\n               pctunder18    pctover64   HSorlower   BAorhigher\nPopulation    0.007594428 -0.020093453 -0.05107553  0.031704662\nmedhhincome  -0.388683691  0.111647722 -0.61927277  0.583703714\nPovertyRate   0.289318732 -0.408377288  0.38428550 -0.244839584\nunemprate     0.426395199 -0.223628488  0.50807715 -0.485070585\nmedvalue     -0.485971837 -0.087907931 -0.59138685  0.716308223\nmedrent      -0.471073339 -0.204393629 -0.59290214  0.673574479\npctwhite     -0.486622092  0.544027226 -0.46090308  0.327834536\npctBlack      0.289877141 -0.227026967  0.16871183 -0.197904602\npctHispanic   0.527563183 -0.424307981  0.56358387 -0.423902133\npctAAPIalone -0.290725828 -0.239911831 -0.25180077  0.384223470\npctunder18    1.000000000 -0.248306018  0.68045309 -0.718007353\npctover64    -0.248306018  1.000000000 -0.14789121 -0.003268322\nHSorlower     0.680453091 -0.147891209  1.00000000 -0.923184800\nBAorhigher   -0.718007353 -0.003268322 -0.92318480  1.000000000\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma |> select(Population:medrent, pctwhite:BAorhigher) |> \n  na.omit() |> \n  DataExplorer::plot_correlation()\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/correlation-2-1.png){width=672}\n:::\n:::\n\n\nAn additional note to the code above is that we selected several continuous variables that we want to inspect, and removed NA values (`use = \"complete.obs\"`) so that the correlation values can be correctly calculated.\n\nWhat can we do if we are interested in statistical associations between **categorical variables**? The typical approach is to use a chi-squared test (see the `chisq.test` function in the `stats` package) in conjunction with visual tools like **barcharts**. We won't delve deeply into the statistical aspect, but we will learn the useful bar plots for displaying summary statistics of categorical data.\n\n### Bar plot\n\nIn the following code, you can see our familiar `group_by` + `summarise` process used to calculate the average median house income by county in Massachusetts. This summarized table is then piped to `ggplot()` for visualization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma |> \n  group_by(county, DesignatedOZ) |>  \n  summarise(\n    Tracts = n(),\n    Income = mean(medhhincome, na.rm=TRUE)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 25 × 4\n# Groups:   county [13]\n   county            DesignatedOZ   Tracts Income\n   <chr>             <chr>           <int>  <dbl>\n 1 Barnstable County Designated          6 46717.\n 2 Barnstable County Not Designated     22 61663.\n 3 Berkshire County  Designated          6 35199 \n 4 Berkshire County  Not Designated     15 51122.\n 5 Bristol County    Designated         12 34573.\n 6 Bristol County    Not Designated     59 42035.\n 7 Dukes County      Not Designated      1 46816 \n 8 Essex County      Designated         20 41358.\n 9 Essex County      Not Designated     50 49966.\n10 Franklin County   Designated          7 41711.\n# ℹ 15 more rows\n```\n\n\n:::\n:::\n\n\n## Exercise 3\n\n1.  Building on the last code block, add `ggplot()` to produce a barchart that shows the summarised income of both designated tracts and undesignated tracts in each county.\n\n    You are going to decide what `geom_` to use and what to put into the `aes()` .\n\n------------------------------------------------------------------------\n\n2.  After you have produced your graph, take a few minutes to read this bar chart below:\n\n![](../img/lab2-emp.png)\n\nThere should be a few differences in this graph compared with what a default function would give us. How can you modify your code above to replicate the bar chart in this image? **In a new code chunk,** please copy and paste your last bar chart code, and try your best to address the following questions.\n\n1.  The bars are put side-by-side instead of stacking on top of one another. [More explainations here](https://r4ds.had.co.nz/data-visualisation.html#position-adjustments). If you don't want a stacked bar chart, you can use one of the three other options: \"identity\", \"dodge\", or \"fill\".\n2.  The x-axis labels are titled to 45 degrees. How can I achieve this? [Hint](https://ggplot2.tidyverse.org/reference/theme.html).\n3.  The labels on the y-axis are formatted in thousands with commas. This can be achieved by modifying the function `scale_y_continuous(labels = scales::percent)` we have seen before. [Hint](https://ggplot2.tidyverse.org/reference/scale_continuous.html).\n4.  Lastly, the counties are not arranged alphabetically, but rather by the income values mapped to the y-axis, starting from large to small. How can I achieve this? [Hint](https://blog.albertkuo.me/post/2022-01-04-reordering-geom-col-and-geom-bar-by-count-or-value/).\n5.  Please add the title, subtitle, x- and y-axis labels, and the data source annotation to your bar chart.\n6.  Please choose a [theme template](https://ggplot2.tidyverse.org/reference/ggtheme.html) for your bar chart.\n\n## Bonus: Scatterplot with marginal histograms\n\nThis is just for fun - If you want to create more advanced statistical plots, there are ways to do that too. The following graph requires an additional package `ggExtra`. But the other syntax should be familiar now.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"ggExtra\")\np <- ggplot(ozs_ma) + \n  geom_point(aes(x = pctBlack, y = PovertyRate, color = DesignatedOZ)) + \n  theme_bw()\nggExtra::ggMarginal(p, type = \"histogram\", groupFill = TRUE)\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/extra-2-1.png){width=672}\n:::\n:::\n\n\n# Work Products\n\nPlease submit **a .qmd file** and **a** **knitted HTML file** that shows your work and responses for each of the **three** **Exercises** included in this lab.\n\nInclude in your document a short write-up of approximately 200 words, that looks back on our questions when we started and discusses what you have found from our analysis so far, with a focus on the State of Massachusetts. You can connect your findings with some broader discussions about Opportunities Zones found [here](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones).\n\nA quick tip: if you include `self_contained = TRUE` in your YAML header, you can create a standalone HTML document without losing the pictures.\n\n![](/img/lab3-html.PNG)\n\nPlease **upload your report to Canvas** **by the end of day, Tuesday, Nov 7.**\n\n### \n",
    "supporting": [
      "lab2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}