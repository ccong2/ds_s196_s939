---
title: "Download and analyze Census data with ![](../img/Rlogo.png){width=60px}"
subtitle: <span style="color:#2C3E50">11.S954 Applied Data Science for Cities</span>
date: "Last Updated `r Sys.Date()`"
format: html
editor: visual
---

# Overview

In this lab, we will use decennial census data and American Community Survey (ACS) data to examine long-term population trends in neighborhoods. These are common sources of historic sociodemographic information, including those that have been pre-processed by sources other than the Census Bureau.

The [Nathalie P. Voorhees Center](https://voorheescenter.uic.edu/) has conducted research on neighborhood and community improvement in the City of Chicago. In [this example](https://voorheescenter.uic.edu/chicago_communities/) below, they calculate the average per capita income for each census tract in Chicago for the years 1970, 1980, 1990, 2000, 2010, and 2017, and then compare it to the regional weighted average income. They have found Chicago has become more segregated by income over time and is losing its middle class.

The study also overlays recent demographic characteristics based on these changes. In the following image, the census tracts are classified into "three cities": those that have increased their share of regional income by 20% or more, those that have changed by less than 20%, and those that have decreased by 20% or more.

![](../img/lab3_chicago_three_cities.PNG)

We will take the idea of the Voorhees Center's study to examine population change patterns in Chicago. Chicago has experienced population decline since its peak in the mid-20th century, attributed to factors including the decline of manufacturing, suburban expansion, and demographic shifts - a phenomenon identified by urban scholars as "Shrinking Cities". We will use historic population census data to show how the trend manifests in Chicago and how it affects across different areas of the city.

Go ahead and start a new .qmd file and remove the template texts, as we always do. These are the packages we are going to use today.

```{verbatim}
# You may need to install the packages: tigris, sf and gt
library(tidyverse)
library(tidycensus)
library(tigris)
library(sf)
library(gt)
```

```{r label="loadpackages", message = FALSE, warning=FALSE}
library(tidyverse)
library(tidycensus)
library(tigris)
library(sf)
library(gt)
```

# Step 1 Collect Population Data

To analyze tract-level population change, we need to gather population data for Chicago across multiple years and make comparisons. Let's first strategize our task: if we can create a dataset like below, with rows being the tracts and columns being the years, we can easily calculate the percentage change in population from 1970 to 2022 for each tract. This percentage change will enable us to categorize areas based on population increases or decreases, similar to the "three cities" methodology used by the Voorhees Center.

| Census Tract | 2022 | 2010 | 1990 | 1970 |
|--------------|:----:|:----:|:----:|:----:|
| 17031822400  | 6012 | 6226 | 5956 | 4336 |
| 17031740100  | 3075 | 3048 | 3297 | 4060 |
| 17031828100  | 5388 | 4844 | 4804 | 5599 |
| 17031826600  | 4872 | 5540 | 5168 | 6290 |

## ACS data in 2022

We will first use `tidycensus` to download data for 2022, you'll need a Census API key (Here is where you can [request one from the census bureau](https://api.census.gov/data/key_signup.html)). After you've signed up for an API key, be sure to activate the key from the email you receive from the Census Bureau so it works correctly.

Declaring `install = TRUE` when calling `census_api_key()` will install the key for use in future R sessions, which may be convenient for many users.

```{verbatim}
census_api_key("yourkeyinquotationmarks", install = TRUE)
```

To complete the API call for ACS data, you will typically need to specify:

-   A desired geography to look up (for example, tract- or block group-level data)
-   The variables we want to look up (we have the [complete variable list](https://api.census.gov/data/2021/acs/acs5/variables.html) for 2022 5-year ACS, you can also retrieve this list by calling `load_variables()`)
-   The state and county names to define your study region.
-   The census year you want data for.
-   The survey you'd like to use (such as ACS 1-, or 5-year data)

The following code returns the number of total population by tract in Cook County, Illinois in 2022. The table we consult is [B01001: Sex by Age](https://data.census.gov/table/ACSDT5Y2020.B01001?q=B01001).

```{r label="2022", message = FALSE, warning=FALSE}
F_2022 <- get_acs(
  geography = "tract",
  state = "IL",
  county = "Cook",
  variables = "B01001_001",
  geometry = TRUE,
  year = 2022)
```

Now you might have seen our first problem: we don't have the option for getting tract-level data for **cities**. We can only obtained data for Cook County, where Chicago is located, but not for the City of Chicago directly. We will come back to it later in our exercise to cut out tracts within Chicago's spatial boundary. That's why we've included the argument `geometry = TRUE`, which will be needed for our spatial processing.

-   `geometry = TRUE` returns a [simple features](https://r-spatial.github.io/sf/articles/sf1.html) (`sf`) object with spatial information saved for each tract. The returned table will include a `geometry` variable that enables spatial analysis.

## Decennial data in 2010

In addition to `get_acs()`, `tidycensus` also provides `get_decennial()` for retrieving data from the US Decennial Census for the years 2000, 2010, and 2020. The function uses similar arguments, as shown below:

```{r label="2010", message = FALSE, warning=FALSE}
F_2010 <- get_decennial(
  geography = "tract", 
  state = "IL",
  county = "Cook",
  variables = "P001001",
  geometry = TRUE,
  year = 2010)
```

## Historic Data in 1990 and 1970

Unfortunately we cannot continue to use `get_decennial()` for the 1990 and 1970 data. The primary reason is the removal of these API endpoints by the Census Bureau. However, there are other factors at play.

1.  **Survey Changes**: After the 2000 Census, the long form decennial survey transitioned into the American Community Survey (ACS).

2.  **Changing Geographies**: Census geographies, which approximate neighborhoods based on population, can change over time. While some tracts remain the same, others may be split if the population increases, or merged if the population decreases.

Analysts often face the challenge of geographic inconsistencies when working with longitudinal data. The Census Bureau's [geographic relationship files](https://www.census.gov/geographies/reference-files/time-series/geo/relationship-files.2020.html) can help show the relationships between geographies over time. To make it easier for researchers, Brown University's [Longitudinal Tract Database](https://s4.ad.brown.edu/projects/diversity/Researcher/Bridging.htm) offers demographic estimates for previous decennial census years---1970, 1980, 1990, and 2000---adjusted to match the 2010 boundaries. This means the tract areas and IDs match the 2010 data, with attribute values adjusted based on area or population share to reflect boundary changes over the years.

Let's get familiar with LTDB data and how to use them. Go to the [data download](https://s4.ad.brown.edu/projects/diversity/researcher/LTBDDload/Default.aspx) page. You will need to enter your email address and certify that you will follow terms of use for the data.

Review the data standard descriptions a bit to see what datasets are available. In our analysis, we will only use the full standard data files for population counts.

![](../img/lab3_ltdb.PNG)

In "**Download Standard Full Data Files**", select the year **1990**, click the download button. Then do the same for **1970**. **It's recommended to download them into a "data" folder in your project directory**.

Now we can import these two datasets using `read_csv`. Simultaneously, we'll use `filter()` to extract only the portion for Cook County.

```{r message = FALSE, warning=FALSE}
F_1990 <- 
  read_csv("../data/LTDB_Std_1990_fullcount.csv") |>
  filter(county == "Cook County" & state == "IL")

F_1970 <- read_csv("../data/LTDB_Std_1970_fullcount.csv")|>
  filter(county == "Cook County" & state == "IL")
```

# Step 2 Compile Datasets

Now we have download four datasets we need, we can start planning how to join them for mapping and further analysis. Joins allow us to merge two datasets based on common attributes, such as GEOID in our case. However, after a quick look at these datasets, there are a few things we may immediately notice:

1\) They have different number of observations. For example, F_2022 (census tracts for the year 2020) contain 1332 observations, F_1970 contains 1317.

> Some census tracts may not have existed in previous years. Our join strategy should prioritize retaining all records from the dataset with more observations. Regarding [types of joins](https://mikoontz.github.io/data-carpentry-week/lesson_joins.html), a `left_join` ensures that all rows from the dataset on the left are preserved in the merged dataset, even if there are no corresponding matches in the dataset on the right.

2\) They have different number of columns, and the column names are not the same across years. For example, the attribute `GEOID` is named as `TRTID10` in the F_1970 and F_1990 datasets.

> We can retain the columns we need by using `select()` , and standardize column names by specifying \[new name\] = \[column name\] in our select calls.

3\) If we do a test `left_join`, we will notice another issue from its error message:

```{verbatim}
left_join(F_2022, F_1990, by = c("GEOID" = "TRTID10"))
```

![](../img/lab3_error_in_join.PNG)

> Some of our GEOID columns are defined as characters while others are numeric, preventing them from directly joining. To resolve this, we can use `mutate()` to convert the column type.

> Alternatively, we can specify the column types when reading the data. When `read_csv()` reads data, it initially examines several rows to infer the format for each column. To override this and explicitly define column formats, we use the `col_types` option in `read_csv()`. For example, `col_types = cols(TRTID10 = col_character())` explicitly defines the column `TRTID10` as character type during data reading.

With all these in mind, let's clean up the datasets for joining. In the following code, I have saved them as new datasets (starting naming with S\_ so that we can keep our original data and come back if we need to)

```{r label="simplify_datasets", message = FALSE, warning=FALSE}
S_1970 <- F_1970 |> 
  # select and rename the columns we need
  select(GEOID = TRTID10, POP70)|> 
  # convert the data type to character
  mutate(GEOID = as.character(GEOID))

S_1990 <- F_1990 |> 
  select(GEOID = TRTID10, POP90) |> 
  mutate(GEOID = as.character(GEOID))

S_2010 <- F_2010 |> 
  select(GEOID, POP10 = value) |> 
  # We are preparing data for non-spatial operations, so I'm using st_drop_geometry to exclude the spatial information here. More about `sf` operations next week.
  st_drop_geometry()

S_2022 <- F_2022 |> 
  select(GEOID, POP22 = estimate) |> 
  st_drop_geometry()
```

Now we are ready to join! An additional trick: a typical `left_join` only works with two datasets at a time. If we want to join four or more datasets, we have to:

```{verbatim}
pop_data <- left_join(S_1990, S_1970, by="GEOID")
pop_data <- left_join(S_2010, pop_data, by="GEOID")
pop_data <- left_join(S_2022, pop_data, by="GEOID")
```

However, we can do this with less code and repetition using the `reduce()` function from the `purrr` package in combination with `left_join()`. Although we haven't introduced it yet, [the `purrr` package](https://purrr.tidyverse.org/) is designed for working with functional programming concepts like loops and recurrence.

```{r message = FALSE, warning=FALSE}
pop_data <-
  reduce(list(S_2022, S_2010, S_1990, S_1970), 
         left_join, by = "GEOID")
```

Our joined result `pop_data` now has the same number of observations as the 2022 dataset - because we placed it on the left side of the `reduce()` function, allowing `left_join()` to apply sequentially from left to right. Now we have a final result structured as intended from the beginning.

![](../img/lab3_example_dataset.PNG)

# Step 3 Calculate and summarize changes

## Compare population changes

### Exercise 1

We have compiled population data in one table. To make this table more informative, let's calculate the percentage change in population for each tract, and classify tracts based on whether their population has significantly decreased, increased, or remained largely unchanged, following the Voohver Center's approach.

![](../img/lab3_example_result.PNG)

Please insert your own code into the document to achieve the following:

1.  Calculate the population change from 1970 to 2022 by computing the percentage increase (POP22 - POP70) / POP70. Use `mutate()` for this and create a new column called "change".

2.  Create another column called "status" to classify the changes. Label changes less than 10% as "Low Change". Label changes greater than 10% as "Growing", and less than -10% as "Declining".

    Note that we also have missing values (NAs) in `change` due to differences in census tracts, where some tracts in 2020 did not exist in earlier years. To account for that I included a fourth category in `status` named "Uncategorized".

**Hint:** How to populate values based on multiple conditions? The traditional and more straightforward approach is using the `if_else()` statement. Combining it with `mutate`, it looks something like this:

```{verbatim}
pop_data |> 
  mutate(status = ifelse(change < -0.1, "declining",
                ifelse(change > 0.1, "growing",
                ifelse(is.na(change), "uncategorized", "low change"))))
```

However, `dplyr` offers a more concise solution. [Check out `case_when`](https://dplyr.tidyverse.org/reference/case_when.html), which simplifies handling multiple conditions by eliminating the need for nested if else statements within multiple parentheses.

```{r echo=FALSE}
pop_data <- pop_data |> 
  mutate(change = (POP22 - POP70)/POP70)|> 
  mutate(Status = case_when(
    is.na(change) ~ "Uncategorized",
    change > 0.10 ~ "Group 1 - Growing",
    change < -0.10 ~ "Group 2 - Declining",
    TRUE ~ "Group 3 - Low Change"
  ))
```

## Create summary tables

When you are ready preparing the dataset in the last step. we can use `group_by()` and `summarise()` to find out how many tracts are in each category.

`` {rlabel="sumtable1", message = FALSE, warning=FALSE} pop_data |> group_by(Status) |>    summarise(`Number of Tracts` = n()) ``

Speaking of summary tables, `gt()`Â is powerful tool for creating presentable and customizable tables with ease. For instance, we can add a few more lines in the previous code to enhance this table by adding titles and colorization. There are also [many other](https://gt.rstudio.com/articles/gt.html) [styling options](https://rfortherestofus.com/2023/08/table-theme-gt) available.

```{r label="sumtable2", message = FALSE, warning=FALSE}
pop_data |> group_by(Status) |> 
  summarise(`Number of Tracts` = n()) |> 
  gt() |> 
  tab_header(title = "Change in Population, 1970-2022",
             subtitle = "Cook County, IL") |> 
  tab_options(column_labels.background.color = 'dodgerblue4')
  

```

# Step 4 Clip out Chicago

As you might have noticed, we are still working with Cook County so far. How is Chicago located within Cook County exactly? Let's visualize that using another census-related package `tigris`.

`tigris` fetches census geographics. You can think of it as a programmatic way of downloading TIGER/Line Shapefiles. It uses geographic entities as [function names](https://github.com/walkerke/tigris). For example, `tracts()` indicates that you want to download tract boundaries, and `county()` indicates you want to download county boundaries, and so on.

The function `place()` fetches census-designated place. The city of Chicago is one of such places in Illinois.

```{r label="tigris", message = FALSE, warning=FALSE}
options(tigris_use_cache=TRUE) # This is to allow tigris to use caching for downloaded data so that we don't need to fetch the same data again every time you need it.

# Download the boundary of Chicago. 
chi_boundary <- places(state = "IL") |> 
  filter(NAME == "Chicago")
```

Recall that we have included spatial information in our F_2022 dataset, which means we can direct plot it. We can also plot both F_2022 and the Chicago boundary together to see the overlay.

```{r label="compare", message = FALSE, warning=FALSE}
ggplot()+
  geom_sf(data = F_2022)+ # boundary of Cook County
  geom_sf(data = chi_boundary, color = "blue", 
          linewidth = 0.5, fill = NA) # boundary of Chicago
```

`st_intersection()` performs a geometric intersection between two spatial objects. When we apply this function on these two spatial files, we can extract the overlapping census tracts within Chicago.

```{r label="cut_chicago", message = FALSE, warning=FALSE}
st_intersection(F_2022, chi_boundary) |> 
  ggplot() +
  geom_sf() 
```

We've got the key method, but in the end, we want to know which tracts in Chicago are "growing", "declining", or "no change", which is in the plain table we have prepared. So what we are going to do next involves two steps: before performing the spatial intersection, we need to reattach the spatial information back to the summary table `pop_data`.

```{r label="join_and_intersection", message = FALSE, warning=FALSE}
# 
chi_pop_data <- 
  # join our result table to the spatial file F_2022
  left_join(F_2022, pop_data, by = "GEOID") |> 
  # Cut it to the Chicago boundary
  st_intersection(chi_boundary) |> 
  # Keep the columns we need
  select(GEOID, POP22:Status)
```

Take a look at your `chi_pop_data`, if everything goes well, we will have a dataset that looks like this.

![](../img/lab3_final_check.PNG)

We've (finally) obtained a column indicating whether each tract's population is growing, declining, or relatively stable in Chicago. Can't wait to put this column into `ggplot`.

```{r label="plot_chicago_1", message = FALSE, warning=FALSE}
ggplot(chi_pop_data) + 
  geom_sf(aes(fill = Status))
```

Feel free to modify the colors, add text, or apply any design touches as you wish.

```{r message = FALSE, warning=FALSE}
ggplot(chi_pop_data) + 
  geom_sf(aes(fill = Status), color = alpha("white", 0.5))+
  scale_fill_manual(values = c(
    "Group 1 - Growing" = "#FC8D59",
    "Group 2 - Declining" = "#D73027",
    "Group 3 - Low Change" = "#FDCC8A",
    "Uncategorized" = "#B0BEC5"
  )) +
  labs(title = "Change in population, 1970-2022",
       subtitle = "City of Chicago, by Census tract")+
  theme_void()
```

### Exercise 2

racial

\% of B/W/A
